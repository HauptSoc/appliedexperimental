---
title: "ðŸ”¬ Simulation-Based Methods versus Theory-Based Methods"
format: 
  revealjs:
    theme: style.scss
editor: source
---

```{r}
#| label: set-up

library(tidyverse)
library(infer)
library(moderndive)
library(lterdatasampler)
library(palmerpenguins)
library(gt)

my_theme <- theme_bw() + 
  theme(axis.title.x = element_text(size = 18), 
        axis.title.y = element_text(size = 18), 
        axis.text.x = element_text(size = 14), 
        axis.text.y = element_text(size = 14), 
        legend.text = element_text(size = 14), 
        legend.title = element_text(size = 18)
        ) 
  
```

# Lab 6 Recap

## Common Mistakes

</br>

::: {.midi}
> Technically, you told me the name of the object that contains the model you decided was best. I want you to tell me the name of the variable(s) included in that model!

:::

Stating what object had the best model (e.g., `one_credits`) but **not** stating
what variable(s) were chosen (e.g., `cls_credits`). 

. . .

At every stage, you are required to state **every** variable included in your "best" model!


# The conclusions we reach depend on our p-value and confidence intervale being reliable.

# The conclusions we reach depend on our p-value and confidence intervale being reliable.

How can we know if they are reliable?

## Model Conditions

For our p-value and confidence interval to be trustworthy, we need to know that the conditions of our model are not violated.

. . .

:::::: columns
::: {.column width="40%"}
::: {.fragment}
For linear regression we are assuming...
:::
:::

::: {.column width="5%"}
:::

::: {.column width="55%"}
::: {.fragment}
**L**inear relationship between $x$ and $y$


**I**ndependent observations (or residuals)


**N**ormality of residuals


**E**qual variance of residuals
:::
:::
::::::

## What happens if the conditions are violated?

In general, when the conditions associated with these methods are violated, we will [underestimate]{.underline} the true standard error (spread) of the sampling distribution.

. . .

-   Our p-values will be **too** small!
-   Our confidence intervals will be **too** narrow!
-   We will make more Type I errors than we expect!

. . .

::: {.callout-important}
# What is a Type I error?
:::

## **L**inear relationship between $x$ and $y$

```{r}
#| fig-align: center
#| label: length-versus-weight-non-linear

and_vertebrates %>%
  filter(species != "Cascade torrent salamander") %>% 
  ggplot(mapping = aes(x = length_1_mm, 
                       y = weight_g, 
                       color = species)) +
  geom_point() + 
  labs(x = "Length (mm)", 
       y = "Weight (g)", 
       color = "Species") +
  my_theme
```

. . .

***What should we do?***

## Variable transformation!

```{r}
#| fig-align: center
#| label: length-versus-weight-transformation

and_vertebrates %>%
  filter(species != "Cascade torrent salamander") %>% 
  ggplot(mapping = aes(x = length_1_mm, 
                       y = weight_g, 
                       color = species)) +
  geom_jitter(alpha = 0.5) + 
  labs(x = "Log Transformed Length (mm)", 
       y = "Log Transformed Weight (g)", 
       color = "Species") +
  scale_x_log10() +
  scale_y_log10() +
  my_theme
```

## **I**ndependence of observations

::::::: columns
::: {.column width="40%"}
The `evals` dataset contains `r nrow(evals)` observations on `r distinct(evals, prof_ID) %>% nrow()` professors. Meaning, professors have **multiple** observations.

</br>

***What should we do?***
:::

::: {.column width="5%"}
:::

:::: {.column width="55%"}
::: fragment
**Best** -- use a random effects model

**Reasonable** -- collapse the multiple scores into a single score
:::
::::
:::::::

## Collapsing Multiple Scores

**Option 1:** Grab a Random Eval

```{r}
#| label: slice-sample-code
#| echo: true
#| eval: false
#| code-line-numbers: false

evals_small <- evals %>% 
  group_by(prof_ID) %>% 
  slice_sample(n = 1)
```

. . .

::: {.small}
```{r}
#| label: slice-sample-glimpse
#| echo: false
#| eval: true
#| 

evals %>% 
  group_by(prof_ID) %>% 
  slice_sample(n = 1) %>% 
  ungroup() %>% 
  gt() %>% 
  tab_style(
    style = cell_text(size = px(14)),
    locations = list(
      cells_body(),
      cells_column_labels()
    )
  ) %>% 
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  )
  
```
:::

## Collapsing Multiple Scores

**Option 2:** Summarize the Evals

```{r}
#| label: min-eval-code
#| echo: true
#| eval: false
#| code-line-numbers: false

evals %>% 
  group_by(prof_ID) %>% 
  mutate(min_score = min(score)) %>% 
  distinct(prof_ID, .keep_all = TRUE)
```

. . .

```{r}
#| label: min-eval-glimpse
#| echo: false
#| eval: true
#| code-line-numbers: false

evals %>% 
  group_by(prof_ID) %>% 
  mutate(min_score = min(score)) %>% 
  distinct(prof_ID, .keep_all = TRUE) %>% 
  ungroup() %>% 
  select(ID, 
         prof_ID, 
         min_score, 
         age, 
         bty_avg, 
         gender, 
         ethnicity, 
         language, 
         rank) %>% 
  gt() %>% 
  tab_style(
    style = cell_text(size = px(14)),
    locations = list(
      cells_body(),
      cells_column_labels()
    )
  )
```


## **E**qual variance of residuals

```{r non-constant-variance}
#| fig-align: center

ggplot(data = hbr_maples, 
       mapping = aes(x = stem_length, y = stem_dry_mass)
       ) +
  geom_point() +
  geom_smooth(method = "lm") +
  labs(
    x = "Stem Length (mm)",
    y = "Stem Dry Mass (g)"
    ) +
  theme_minimal() + 
  my_theme
```

. . .

***What should we do?***

## Variable transformation!

```{r}
ggplot(data = hbr_maples, 
       mapping = aes(x = stem_length, y = stem_dry_mass)
       ) +
  geom_point() +
  geom_smooth(method = "lm") +
  labs(
    x = "Stem Length (mm)",
    y = "Log Transformed Stem Dry Mass (g)"
  ) +
  theme_minimal() + 
  scale_y_log10() +
  my_theme
```

## **N**ormality of residuals

```{r}
#| label: non-normal

fish <- and_vertebrates %>%
  filter(!species %in% c("Cascade torrent salamander", 
                         "Coastal giant salamander")
         ) 

curved_lm <- lm(weight_g ~ length_1_mm, data = fish)

get_regression_points(curved_lm) %>% 
  ggplot(mapping = aes(x = residual)) + 
  geom_histogram() + 
  labs(x = "Residual") +
  my_theme
```

. . .

***What should we do?***

## Variable transformation!

```{r normal}

fish <- and_vertebrates %>%
  filter(!species %in% c("Cascade torrent salamander", "Coastal giant salamander"))

not_curved_lm <- lm(log(weight_g) ~ log(length_1_mm), data = fish)

broom::augment(not_curved_lm) %>% 
  mutate(.resid = `log(weight_g)` - `.fitted`) %>% 
  ggplot(mapping = aes(x = .resid)) + 
  geom_histogram(binwidth = 0.1) + 
  labs(x = "Residual") +
  xlim(c(-0.5, 0.5)) +
  my_theme
```

## What if we can't fix a condition being violated?

. . .

::::::: columns
::: {.column width="45%"}
For the **L**, **I**, and **E** conditions...

we need to ask for help!
:::

::: {.column width="5%"}
:::

:::: {.column width="45%"}
::: fragment
For the **N** condition...

we need to use simulation instead of mathematical formulas to get our p-value and confidence interval.
:::
::::
:::::::

# Simulation-Based Methods versus Theory-Based Methods

## Mathematical / Theory-based Methods

::: incremental
-   Are a "simpler" approach
-   Use formulas instead of simulation to obtain standard error
-   Use a named distribution (e.g., $t$-distribution) to get p-value and confidence interval
-   Require that the residuals are normally distributed
:::

## How does this look?

:::: panel-tabset
## Before

```{r}
#| echo: true
#| label: obs-slope-code
#| code-line-numbers: false

obs_slope <- evals %>% 
  specify(response = score, 
          explanatory = bty_avg) %>% 
  calculate(stat = "slope")
```

```{r}
#| label: obs-slope
pull(obs_slope)
```

## Now

::: small
```{r}
#| echo: true
#| label: obs-t-code
#| code-line-numbers: false

evals_lm <- lm(score ~ bty_avg, data = evals)

get_regression_table(evals_lm)
```
:::

```{r}
#| label: obs-t
#| include: false

evals_lm <- lm(score ~ bty_avg,
               data = evals)

coef_table <- get_regression_table(evals_lm)

t_stat <- filter(coef_table, term == "bty_avg") %>% 
  select(statistic)

slope_stat <- filter(coef_table, term == "bty_avg") %>% 
  select(estimate)

t_stat
```
::::

## 

::: {style="font-size: 2em; color: #000000;"}
How did R calculate the $t$-statistic?
:::

::::::: panel-tabset
## Step 1: SE

:::::: columns
::: {.column width="40%"}
$SE_{b_1} = \frac{\frac{s_y}{s_x} \cdot \sqrt{1 - r^2}}{\sqrt{n - 2}}$
:::

::: {.column width="5%"}
:::

::: {.column width="55%"}
```{r}
se_num <- ( sd(evals$score) / sd(evals$bty_avg) ) * 
  sqrt(
    1 - cor(evals$score, evals$bty_avg)
    ) 

se_denom <- sqrt(nrow(evals) - 2)

se <- se_num / se_denom

se
```
:::
::::::

## Step 2: t-statistic

$t = \frac{b_1}{SE_{b_1}} = \frac{`r slope_stat`}{`r se`} = `r slope_stat / se`$

## Proof!

::: {.small}
```{r}
get_regression_table(evals_lm) 
```
:::
:::::::

## How does R calculate the p-value?

. . .

```{r}
#| fig-align: center
#| out-width: 50%

ggplot(data = tibble(x = c(-5, 5)), 
       mapping = aes(x)) +
  stat_function(fun = dt, 
                args = list(df = nrow(evals) - 2), 
                color = "blue", 
                linewidth = 1.5) +
  labs(y = "", 
       x = "t-statistic") +
  scale_y_continuous(breaks = NULL) +
  geom_vline(xintercept = pull(t_stat), color = "red", linewidth = 1.5) +
  my_theme

```

. . .

::: callout-note
# Different $t$-distributions

A $t$-distribution has a *slightly* different shape depending on the sample size. In simple linear regression, we are using a $t$-distribution with $n - 2$ degrees of freedom to get our p-value. In multiple linear regression, this becomes $n - $ the # of unique slopes and intercepts.
:::

# Did we get similar results between these methods?

# Did we get similar results between these methods?

Why do you think that is?

## Approximating the permutation distribution

:::::: columns
::: {.column width="40%"}
A $t$-distribution can be a reasonable approximation for the permutation distribution [if the normality condition is not violated]{.underline}.
:::

::: {.column width="5%"}
:::

::: {.column width="55%"}
```{r t-distribution}
plot(c(-5, 5),
     c(0, dnorm(0)),
      type = "n", 
     ylab = "", 
     xlab = "",
     axes = FALSE
     )

at <- seq(-10, 10, 2)
axis(1, at)
axis(1, at - 1, rep("", length(at)), tcl = -0.1)
abline(h = 0)
COL. <- openintro::fadeColor(openintro::IMSCOL["blue", "full"], c("FF", "89", "68", "4C", "33"))
COLt <- openintro::fadeColor(openintro::IMSCOL["blue", "full"], c("FF", "AA", "85", "60", "45"))
DF <- c("normal", 8, 4, 2, 1)
X <- seq(-10, 10, 0.02)
Y <- dnorm(X)
lines(X, Y, col = COL.[1])

for (i in 2:5) {
  Y <- dt(X, as.numeric(DF[i]))
  lines(X, Y, col = COL.[i], lwd = 1.5)
}
legend(2.5, 0.4,
  legend = c(
    DF[1],
    paste("t, df = ", DF[2:5], sep = "")
  ),
  col = COL.,
  text.col = COLt,
  lty = rep(1, 5),
  lwd = 1.5
)

```
:::
::::::

## Your next tasks...

1. Complete the grade check-in activity
2. Learn about ANOVA in the context of multiple linear regression
3. Use an ANOVA to decide what model you would have chosen for the midterm 
project (Statistical Critique #2)
4. Revise Lab 6

