---
title: "Variable Selection in Multiple Regression"
format: 
  revealjs:
    theme: style.scss
editor: source
---

```{r set-up}
library(tidyverse)
library(moderndive)
library(palmerpenguins)
```

# Reminders About Deadlines

## Revision Deadlines

-   Lab 3 revisions are due on Wednesday (May 7)

-   Statistical Critique revisions are due Wednesday (May 7)

-   Lab 4 revisions are due on Friday (May 9)

## Lab 3 Revisions

::: small
1.  Log in to [Posit Cloud](https://posit.cloud/)
2.  Open your Weeks 2-3 Group Workspace
3.  Find Lab 3
:::

![](images/find-lab.png){fig-alt="A screenshot of a group's Lab 2 project in their group workspace. There is a purple box around an icon with two boxes that has a 'plus' (+) symbol in the middle."}

::::::: columns
:::: {.column width="40%"}
::: small
4.  Make a personal copy of your group's Lab 3
:::
::::

::: {.column width="5%"}
:::

::: {.column width="55%"}
![](images/make-a-copy.png){width="50%" fig-alt="A screenshot of the pop-up that appears when you click on the 'Make a copy' icon next to the Lab 2 project."}
:::
:::::::

:::: small
::: callout-important
# Every member must have their own copy of the lab! No one works in the original document.
:::
::::

# Lab 4

::: {.small}
::: {.incremental}
- Question 8: Write out the estimated regression equation
    + Your equation needs to indicate the explanatory and response variables
    (not x and y).
    + Your equation needs to indicate that the response is *estimated*, not
    an exact value. 
:::
:::

. . .

::: {.small}
::: columns
::: {.column width="47%"}
- Question 9: Interpret the slope coefficient
    + If you increase `year` by 1, how much do you expect the 
    `ice duration` to change?

:::

::: {.column width="5%"}
:::

::: {.column width="45%"}
::: {.fragment}
- Question 10: A different slope interpretation
    + If you increase `year` by 100, how much do you expect the 
    `ice duration` to change?
:::
:::
:::
:::

# Model Selection

# Model Selection

</br>

**What is model selection?**

. . .

**Why use model selection?**

## 1.  Lots of available predictor variables

`evals`:

```{r}
#| echo: false

slice_sample(evals, n = 3) |> 
  knitr::kable() |> 
  kableExtra::kable_styling()
```

## 2.  Interested in prediction not explanation

. . .

> You want to predict an outcome variable $y$ based on the information contained in a set of predictor variables $x$. You don't care so much about understanding how all the variables relate and interact with one another, but rather only whether you can make good predictions about $y$ using the information in $x$.
>
> *ModernDive*

## How do you use model selection?

. . .

:::::: columns
::: {.column width="45%"}
-   Stepwise Selection
    -   Forward Selection
    -   Backward Selection
:::

::: {.column width="5%"}
:::

::: {.column width="45%"}
-   Resampling Methods
    -   Cross Validation
    -   Testing / Training Datasets
:::
::::::

. . .

::: {style="font-size: 0.9em; color: #e28743;"}
**With any of these methods, you get to choose *how* you decide if one model is better than another model.**
:::

# Model Comparison Measures

## $R^2$ -- Coefficient of Determination

<!-- Wright was one of the giants of 20th century evolutionary biology. -->

:::::::: columns
:::: {.column width="45%"}
![](images/wright.jpg){fig-alt="A headshot of Sewall Wright in front of a chalkboard. Sewall is a white man with small black glasses, appears to be roughly 60 in this image."}

::: {style="font-size: 0.75em;"}
Wright, Sewall (1921). Correlation and Causation. *Journal of Agricultural Research* 20: 557-585.
:::
::::

::: {.column width="5%"}
:::

:::: {.column width="45%"}
::: {style="font-size: 0.75em;"}
> In statistics, the coefficient of determination, denoted $R^2$ or $r^2$ and pronounced "R squared," is the proportion of the variation in the dependent variable that is predictable from the independent variable(s).
>
> *Wikipedia*
:::
::::
::::::::

## $R^2 = 1 - \frac{\text{var}(\text{residuals})}{\text{var}(y)}$

-   $\text{var}(\text{residuals})$ is the variance of the residuals "leftover" from the regression model

-   $\text{var}(y)$ is the inherent variability of the response variable

. . .

::: {style="font-size: 1.5em; color: #e28743;"}
Suppose we have a simple linear regression with an $R^2$ of 0.85. How would you interpret this quantity?
:::

## Wait! 

$R^2$ **always** increases as you increase the number of explanatory variables.

. . .

</br>

::: {style="color: #e28743;"}
The variance of the residuals will **always** decrease when you include additional explanatory variables.
:::

:::::: columns
::: {.column width="45%"}
**Simple Linear Regression**

$0.85 = 1 - \frac{0.75}{5}$
:::

::: {.column width="5%"}
:::

::: {.column width="45%"}
**One Additional Variable**

$0.86 = 1 - \frac{0.7}{5}$
:::
::::::

## Adjusted $R^2$

:::::::: columns
:::: {.column width="45%"}
![](images/ezekiel.jpeg){fig-alt="An image of Mordaeai Ezekiel at a desk writing on a notebook. Mordecai is a #FFFFFF man with small glasses and appears to be in his late 30s."}

::: {style="font-size: 0.75em;"}
Mordecai Ezekiel (1930). Methods Of Correlation Analysis, Wiley, p. 208-211.
:::
::::

::: {.column width="5%"}
:::

:::: {.column width="45%"}
::: {style="font-size: 0.75em;"}
> The use of an adjusted $R^2$ is an attempt to account for the phenomenon of the $R^2$ automatically increasing when extra explanatory variables are added to the model.
>
> *Wikipedia*
:::
::::
::::::::

## $R^2_{adj} = 1 - R^2 \times \frac{(n - 1)}{(n - k - 1)}$

-   $n$ is the sample size

-   $k$ is the number of coefficients needed to be calculated

. . .

::: {style="font-size: 1.2em; color: #e28743;"}
Suppose you have a categorical variable with 4 levels included in your
**parallel slopes** multiple linear regression.

> What value will you use for $k$ in the calculation of $n - k - 1$?
:::

## p-values

:::::::: columns
:::: {.column width="45%"}
![](images/fisher.jpeg){fig-alt="A headshot of Ronald Fisher, the famous Statistician from the 1950s. Fisher is pictured with small glasses that are seemingly attached with a single strand of wire. He appears to be in his early 30s."}

::: {style="font-size: 0.75em;"}
Fisher R. A. (1950). Statistical Methods for Research Workers.
:::
::::

::: {.column width="5%"}
:::

:::: {.column width="45%"}
::: {style="font-size: 0.75em;"}
> In null-hypothesis significance testing, the p-value is the probability of obtaining test results at least as extreme as the result actually observed, under the assumption that the null hypothesis is correct. A very small p-value means that such an extreme observed outcome would be very unlikely under the null hypothesis.
>
> *Wikipedia*
:::
::::
::::::::

<!-- ## How do you use p-values to choose a "best" model? -->

<!-- Make a slide here! -->

## AIC

:::::::: columns
:::: {.column width="55%"}
```{r}
#| out-width: 40%
#| fig-alt: "An image of the famous Japanese statistician Akaike in a nice blue suit at a formal event. Akaike appears to be older with grey hair and larger glasses."
knitr::include_graphics("images/akaike.jpg")
```

::: {style="font-size: 0.75em;"}
Akaike, H. (1973). Information theory and an extension of the maximum likelihood principle.
:::
::::

::: {.column width="5%"}
:::

:::: {.column width="40%"}
::: {style="font-size: 0.6em;"}
> The Akaike information criterion (AIC) is an estimator of prediction error and thereby relative quality of statistical models for a given set of data. Given a collection of models for the data, AIC estimates the quality of each model, relative to each of the other models.
>
> *Wikipedia*
:::
::::
::::::::

## How do you use AIC to choose a "best" model?

</br>

::: {style="font-size: 0.75em;"}
```{r}
#| echo: false

full_aic <- lm(body_mass_g ~ ., data = penguins) %>% 
  AIC()

minus_year <- lm(body_mass_g ~ . - year, data = penguins) %>% 
  AIC()

minus_species <- lm(body_mass_g ~ . - species, data = penguins) %>% 
  AIC()

minus_flipper <- lm(body_mass_g ~ . - flipper_length_mm, data = penguins) %>% 
  AIC()

aic_table <- tibble(model = 
                      c("Full Model", "All Variables Except Year", 
                        "All Variables Except Species", 
                        "All Variables Except Flipper Length"), 
                    AIC = c(full_aic, 
                            minus_year, 
                            minus_species, 
                            minus_flipper)
                    ) %>% 
  mutate(`Delta AIC` = AIC - min(AIC))

aic_table %>% 
  arrange(`Delta AIC`) %>% 
  knitr::kable() %>% 
  kableExtra::kable_styling()

```
:::

. . .

</br>

::: {style="font-size: 0.75em; color: #e28743;"}
If you've ever assessed whether $\Delta$ AIC $> 2$ you have done something that is mathematically close to $p < 0.05$.
:::

# Model Selection Activity!

## Backward Selection by Hand

-   Start with "full" model (every explanatory variable is included)
    -   Use adjusted $R^2$ to summarize the "fit" of this model
-   Decide which **one** variable to remove
    -   Highest adjusted $R^2$
-   Decide what **one** variable to remove next
    -   Highest adjusted $R^2$
-   Keep removing variables until adjusted $R^2$ doesn't increase

# What's your best model?

## Adding a Constraint

Repeat the same process, but now for a variable to be removed the adjusted $R^2$ must increase by **at least** 2% (0.02).

## 

::: {style="font-size: 4em;"}
What's your best model?
:::

## If you're not interested in prediction, what should you use instead?

> In fact, many statisticians discourage the use of stepwise regression alone for model selection and advocate, instead, for a more thoughtful approach that carefully considers the research focus and features of the data.
>
> *Introduction to Modern Statistics*

# For Wednesday

## Peer Review

Please print your Midterm Project and bring it to class!
