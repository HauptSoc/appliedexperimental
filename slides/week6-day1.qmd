---
title: "Variable Selection in Multiple Regression"
format: 
  revealjs:
    theme: style.scss
editor: visual
---

```{r set-up}
library(tidyverse)
library(moderndive)
library(palmerpenguins)
```

# Statistical Critique

## Feedback & Revisions

::: incremental
::: small
-   You are expected to directly state what variable(s) are associated with each aesthetic (e.g., the x-axis is associated with time).

-   Aesthetics are associated with **variables**

    -   If there is only one color / shape / linetype being used in the plot, it is not associated with a variable!
    -   If there are multiple plots, then there is a variable associated with how the plots are separated!
:::
:::

:::{.callout-caution}
# Revision Deadline
Revisions for Statistical Critiques are due next Thursday (February 22)
:::

# Midterm Project

## Research Questions

:::{.incremental}
-   Your research question should be a [question]{.underline} 

-   Your question should be able to be addressed with a [multiple linear regression]{.underline} 

    * Is the relationship between stem length and stem dry mass different for watersheds treated with calcium versus without?
    * What is the relationship between the size of a fiddler crab and the latitude and water temperature in which it lives?
:::

## Data Visualizations & Coefficient Interpretations

-   Descriptions of your visualizations should address:
    * form, direction, strength, and unusual points

-   You should interpret **every** coefficient from your regression equation(s)! 
    * Every y-intercept and every slope

## Study Limitations -- Scope of Inference

Based on how the study was designed, 

:::{.fragment}
:::{.small}
what population can you infer these results onto?

:::{.small}
  * Every sugar maple? 
  * Sugar maples in the Northeast? 
  * Sugar maples in New Hampshire?
  * Sugar maples in the Hubbard Brook Experimental Forest?
  * Sugar maples in similar areas of the Hubbard Brook Experimental Forest to those that were sampled? 
  * This sample of sugar maples?
:::
:::
:::

. . .

Why?

## Study Limitations -- Causal Inference

Based on how the study was designed, 

:::{.fragment}
:::{.small}
what can you say about the relationships between the variables?

  * Can you say that your explanatory variable(s) [causes]{.underline} changes in your response variable? 
  * Why or why not?
  * What can you say about these relationships?
:::
:::


## Writing Conclusions

- Circle back to your research question 
- What did you learn in your visualizations?
- What did you learn in your regression model?
- What conclusions would you reach about your research question?

:::{.callout-caution}
# No "significance" & no p-values
:::

# Model Selection

## 

::: {style="font-size: 2.5em; color: #76b5c5;"}
**What is model selection?**
:::

. . .

</br> </br>

::: {style="font-size: 2.5em; color: #e28743;"}
**Why use model selection?**
:::

## 

::: {style="font-size: 1.5em;"}
1.  Lots of available predictor variables
:::

`evals`:

```{r}
#| echo: false

slice_sample(evals, n = 3) |> 
  knitr::kable() |> 
  kableExtra::kable_styling()
```

## 

::: {style="font-size: 1.5em;"}
2.  Interested in prediction not explanation
:::

. . .

> You want to predict an outcome variable $y$ based on the information contained in a set of predictor variables $x$. You don't care so much about understanding how all the variables relate and interact with one another, but rather only whether you can make good predictions about $y$ using the information in $x$.
>
> *ModernDive*

## 

::: {style="font-size: 2em; color: #76b5c5;"}
How do you use model selection?
:::

. . .

::: columns
::: {.column width="45%"}
-   Stepwise Selection
    -   Forward Selection
    -   Backward Selection
:::

::: {.column width="5%"}
:::

::: {.column width="45%"}
-   Resampling Methods
    -   Cross Validation
    -   Testing / Training Datasets
:::
:::

. . .

::: {style="font-size: 0.9em; color: #e28743;"}
**With any of these methods, you get to choose *how* you decide if one model is better than another model.**
:::

# Model Comparison Measures

## 

::: {style="font-size: 2em; color: #76b5c5;"}
$R^2$ -- Coefficient of Determination
:::

<!-- Wright was one of the giants of 20th century evolutionary biology. -->

::: columns
::: {.column width="45%"}
![](images/wright.jpg)

::: {style="font-size: 0.75em;"}
Wright, Sewall (1921). Correlation and causation. Journal of Agricultural Research 20: 557-585.
:::
:::

::: {.column width="5%"}
:::

::: {.column width="45%"}
::: {style="font-size: 0.75em;"}
> In statistics, the coefficient of determination, denoted $R^2$ or $r^2$ and pronounced "R squared," is the proportion of the variation in the dependent variable that is predictable from the independent variable(s).
>
> *Wikipedia*
:::
:::
:::

## 

::: {style="font-size: 2em"}
$R^2 = 1 - \frac{\text{var}(\text{residuals})}{\text{var}(y)}$
:::

-   $\text{var}(\text{residuals})$ is the variance of the residuals "leftover" from the regression model

-   $\text{var}(y)$ is the inherent variability of the response variable

. . .

::: {style="font-size: 1.5em; color: #e28743;"}
Suppose we have a simple linear regression with an $R^2$ of 0.85. How would you interpret this quantity?
:::

## 

::: {style="font-size: 1.5em;"}
But! $R^2$ **always** increases as you increase the number of explanatory variables.
:::

. . .

</br>

::: {style="color: #e28743;"}
The variance of the residuals will **always** decrease when you include additional explanatory variables.
:::

::: columns
::: {.column width="45%"}
**Simple Linear Regression**

$0.85 = 1 - \frac{0.75}{5}$
:::

::: {.column width="5%"}
:::

::: {.column width="45%"}
**One Additional Variable**

$0.86 = 1 - \frac{0.7}{5}$
:::
:::

## 

::: {style="font-size: 2em; color: #76b5c5;"}
Adjusted $R^2$
:::

::: columns
::: {.column width="45%"}
![](images/ezekiel.jpeg)

::: {style="font-size: 0.75em;"}
Mordecai Ezekiel (1930). Methods Of Correlation Analysis, Wiley, pp. 208-211.
:::
:::

::: {.column width="5%"}
:::

::: {.column width="45%"}
::: {style="font-size: 0.75em;"}
> The use of an adjusted $R^2$ is an attempt to account for the phenomenon of the $R^2$ automatically increasing when extra explanatory variables are added to the model.
>
> *Wikipedia*
:::
:::
:::

## 

::: {style="font-size: 1.25em"}
$R^2_{adj} = 1 - R^2 \times \frac{(n - 1)}{(n - k - 1)}$
:::

-   $n$ is the sample size

-   $k$ is the number of coefficients needed to be calculated

. . .

::: {style="font-size: 1.2em; color: #e28743;"}
Suppose you have a two categorical variables included in your regression, one with 7 levels and one with 4 levels.

> What value will you use for $k$ in the calculation of $n - k - 1$?
:::

## 

::: {style="font-size: 2em; color: #76b5c5;"}
p-values
:::

::: columns
::: {.column width="45%"}
![](images/fisher.jpeg)

::: {style="font-size: 0.75em;"}
Fisher R. A. (1950). Statistical methods for research workers. 
:::
:::

::: {.column width="5%"}
:::

::: {.column width="45%"}
::: {style="font-size: 0.75em;"}
> In null-hypothesis significance testing, the p-value is the probability of obtaining test results at least as extreme as the result actually observed, under the assumption that the null hypothesis is correct. A very small p-value means that such an extreme observed outcome would be very unlikely under the null hypothesis.
>
> *Wikipedia*
:::
:::
:::

## 

::: {style="font-size: 2em; color: #76b5c5;"}
AIC
:::

::: columns
::: {.column width="55%"}
```{r}
#| out-width: 40%
knitr::include_graphics("images/akaike.jpg")
```

::: {style="font-size: 0.75em;"}
Akaike, H. (1973). Information theory and an extension of the maximum likelihood principle. 
:::
:::

::: {.column width="5%"}
:::

::: {.column width="40%"}
::: {style="font-size: 0.6em;"}
> The Akaike information criterion (AIC) is an estimator of prediction error and thereby relative quality of statistical models for a given set of data. Given a collection of models for the data, AIC estimates the quality of each model, relative to each of the other models.
>
> *Wikipedia*
:::
:::
:::

## 

::: {style="font-size: 1.5em; color: #76b5c5;"}
How do you use AIC to choose a "best" model?
:::

. . .

</br>

::: {style="font-size: 0.75em;"}
```{r}
#| echo: false

full_aic <- lm(body_mass_g ~ ., data = penguins) %>% 
  AIC()

minus_year <- lm(body_mass_g ~ . - year, data = penguins) %>% 
  AIC()

minus_species <- lm(body_mass_g ~ . - species, data = penguins) %>% 
  AIC()

minus_flipper <- lm(body_mass_g ~ . - flipper_length_mm, data = penguins) %>% 
  AIC()

aic_table <- tibble(model = 
                      c("Full Model", "All Variables Except Year", 
                        "All Variables Except Species", 
                        "All Variables Except Flipper Length"), 
                    AIC = c(full_aic, 
                            minus_year, 
                            minus_species, 
                            minus_flipper)
                    ) %>% 
  mutate(`Delta AIC` = AIC - min(AIC))

aic_table %>% 
  arrange(`Delta AIC`) %>% 
  knitr::kable() %>% 
  kableExtra::kable_styling()

```
:::

. . .

</br>

::: {style="font-size: 0.75em; color: #e28743;"}
If you've ever assessed whether $\Delta$ AIC $> 2$ you have done something that is mathematically close to $p < 0.05$.
:::

## 

::: {style="font-size: 4em; color: #B6CADA;"}
Model Selection Activity!
:::

## 

::: {style="font-size: 2em; color: #B6CADA;"}
What should you use instead?
:::

> In fact, many statisticians discourage the use of stepwise regression alone for model selection and advocate, instead, for a more thoughtful approach that carefully considers the research focus and features of the data.
>
> *Introduction to Modern Statistics*

# For Thursday

## Peer Review

Please print your Midterm Project and bring it to class! 
