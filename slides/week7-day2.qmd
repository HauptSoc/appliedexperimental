---
title: "üßëüèΩ‚Äçüî¨ P-values & Hypothesis Tests"
format: 
  revealjs:
    theme: style.scss
editor: source
---

```{r set-up}
library(tidyverse)
library(infer)
library(moderndive)
library(lterdatasampler)

null_dist <- hbr_maples %>% 
  specify(response = stem_dry_mass,
          explanatory = stem_length) %>% 
  hypothesize(null = "independence") %>% 
  generate(reps = 1000, type = "permute") %>% 
  calculate(stat = "slope") 
```

# Plan for the rest of the quarter

## Weeks 8, 9, & 10

::::::::: columns
:::: {.column width="30%"}
::: fragment
**Week 8**

::: {.small}
-   Dig deeper into model conditions
-   Learn about One-Way ANOVA
-   Compare "visual" model selection with p-value model selection (Stat Critique #2)
:::
:::
::::

:::: {.column width="30%"}
::: fragment
**Week 9**

::: {.small}
-   Learn about simulation-based and theory-based inference for one-way ANOVA
-   First draft of Final Project
:::
:::
::::

:::: {.column width="30%"}
::: fragment
**Week 10**

::: {.small}
-   Learn about two-way ANOVA
-   Finish Final Project (poster)
:::
:::
::::
:::::::::

## Upcoming Deadlines

-   Lab 4 revisions are due on Friday (May 16)
-   Lab 3 second revisions are due on Friday (May 16)

::: callout-note
# Revision Deadlines

If you did not submit revisions by the deadline (or forgot to include your
reflections), your assignment **is not** eligible for additional revisions.
:::

## 

::: {style="font-size: 4em; color: #000000;"}
you...
:::

::: {style="font-size: 1.25em; color: #000000;"}
-   understand the importance of sampling variability
-   know about using confidence intervals to estimate a range of plausible values for the population parameter
-   want to know how p-values fit in
:::

##  {background-color="#B6CADA"}

::: {style="font-size: 2.5em; color: #000000;"}
What if I want to know if the population parameter differs from a specific value?
:::

. . .

<center>

::: {style="font-size: 3em; color: #0F4C81;"}
Hypothesis test!
:::

</center>

## 

::: {style="font-size: 3em; color: #000000;"}
Hypothesis test goal:
:::

::: {style="font-size: 1.5em; color: #000000;"}
Assess how different what we saw in our data is from what could have happened if the null hypothesis was true\*
:::

. . .

::: {style="font-size: 0.75em;"}
\*For hypothesis tests, we live in an alternative universe where $H_0$ is true
:::

## How can we approximate what could have happened if the null was true?

. . .

::: {style="font-size: 2em; color: #ed8402;"}
Permutation!
:::

## A Permutation Resample

::: incremental
-   Assumes the original sample is "representative" of observations in the population

-   Uses the original sample to generate new samples that might have occurred if the null hypothesis was true.
:::

. . .

::: {style="color: #34605f;"}
We can use statistics from these resamples to approximate the true sampling distribution under the null!
:::

# Why do we want a sampling distribution?

## Testing a Population Parameter

::: incremental
-   Like before, we are interested in knowing how a statistic varies from sample to sample.

-   Knowing a statistic's behavior helps us make better / more informed decisions!

-   This helps us know what statistics are more or less likely to occur [if the null hypothesis is true]{style="color: #e28743"}.
:::

# p-values

. . .

::: {style="font-size: 1.5em; color: #000000;"}
> Quantify how "surprising" what we saw in our data is, if the null hypothesis was true
:::

## How do I get a p-value?

. . .

<center>

::: {style="font-size: 2em; color: #ed8402;"}
Permuting!
:::

. . .

::: small
1.  From your original sample, separate the $x$ values from the $y$ values.

2.  Create new ordered pairs by randomly pairing $x$ values with $y$ values (permuting the labels).
:::

. . .

<center>

::: {style="font-size: 0.75em; color: #ed8402;"}
This is your permuted resample.
:::

</center>

. . .

::: small
3.  Repeat this process many, many times.
:::

. . .

::: small
4.  Calculate a numerical summary (e.g., slope) for each permutation resample.
:::

. . .

<center>

::: {style="font-size: 0.75em; color: #ed8402;"}
These are your permuted statistics.
:::

</center>

## Permutation Distribution

. . .

> [*definition*: a distribution of the]{style="color: #000000;"} [*permuted statistics*]{style="color: #e28743;"} [from every]{style="color: #000000;"} [*permuted resample*]{style="color: #e28743;"}

. . .

Displays the variability in the statistic that could have happened with repeated sampling, **if the null hypothesis was true**.

. . .

::: {style="color: #e28743;"}
Approximates the true sampling distribution under the null!
:::

## 

::: {style="font-size: 2em; color: #000000;"}
How do I get my p-value?
:::

. . .

Compare the observed statistic with the statistics produced assuming the null hypothesis was true.

. . .

</br>

::: {style="font-size: 1.25em;"}
A p-value summarizes the [**probability**]{style="color: #76b5c5;"} of obtaining a sample statistic [as or more extreme than what we observed]{.underline}, [**if the null hypothesis was true**]{style="color: #76b5c5;"}.
:::

<!-- add slides about HT decisions -->

## What is one similarity and one difference between a permutation distribution and a bootstrap distribution?

:::::::: columns
:::: {.column width="45%"}
::: {style="font-size: 1.5em;"}
Similarity
:::

::: {.small}
Distributions of sample statistics

Use resampling to see variability

Approximate a sampling distribution

Use observed data
:::
::::

::: {.column width="5%"}
:::

:::: {.column width="45%"}
::: {.fragment}
::: {style="font-size: 1.5em;"}
Difference
:::

::: {.small}
Permutation distributions assume $H_0$ is true

Bootstrapping resamples with replacement
:::
:::
::::
::::::::

## Exploring the `hbr_maples` dataset!

:::::: columns
::: {.column width="40%"}
![](images/hbr_maples.jpg)
:::

::: {.column width="5%"}
:::

::: {.column width="55%"}
`stem_length`: a number denoting the height of the seedling in millimeters

`stem_dry_mass`: a number denoting the dry mass of the stem in grams
:::
::::::

## 

```{r seedlings-slr}
#| echo: false

library(lterdatasampler)

ggplot(data = hbr_maples, 
       mapping = aes(x = stem_length, y = stem_dry_mass)
       ) +
  geom_point() +
  geom_smooth(method = "lm") +
  labs(
    x = "Stem Length (mm)",
    y = "Stem Dry Mass (g)",
    title = "Sugar Maple Seedlings in Hubbard Brook LTER"
  ) +
  theme_minimal() + 
  theme(axis.title.x = element_text(size = 18),
        axis.title.y = element_text(size = 18), 
        axis.text.x = element_text(size = 12), 
        axis.text.y = element_text(size = 12), 
        plot.title = element_text(size = 24)
        )
```

. . .

::: {style="font-size: 1.5em; color: #76b5c5;"}
**What condition do we need to be worried about?**
:::

## In this sample of `r nrow(hbr_maples)` sugar maples...

```{r lm-table}
length_mass_lm <- lm(stem_dry_mass ~ stem_length, data = hbr_maples)

regression_table <- get_regression_table(length_mass_lm) 

intercept <- filter(regression_table, term == "intercept") %>% 
  pull(estimate)

slope <- filter(regression_table, term == "stem_length") %>% 
  pull(estimate)

```

$$\widehat{\text{stem dry mass}} = `r round(intercept, digits = 3)` + `r round(slope, digits = 3)` \times \text{stem length}$$

. . .

</br>

::: {style="font-size: 1.5em;"}
What slope could have happened if there was **no** relationship between stem length and stem dry mass?
:::

## Generating a permuted resample and calculating permuted statistics

</br>

. . .

**Step 1:** `specify()` your response and explanatory variables

. . .

**Step 2:** `hypothesize()` what would happen under the null

. . .

**Step 3:** `generate()` permuted resamples

. . .

**Step 4:** `calculate()` the statistic of interest

## Step 1: Specify your variables!

```{r}
#| eval: false
#| label: specify
#| echo: true

hbr_maples %>% 
  specify(response = stem_dry_mass,
          explanatory = stem_length)
```

## Step 2: State your hypothesis!

```{r}
#| eval: false
#| label: hypothesize
#| echo: true

hbr_maples %>% 
  specify(response = stem_dry_mass,
          explanatory = stem_length) %>% 
  hypothesize(null = "independence")
```

</br>

`"independence"` -- the assumed relationship between the explanatory and response variables under the null hypothesis

. . .

::: callout-tip
# Independence of variables

Note! This is different from assuming your observations are independent!
:::

## Step 3: Generate your resamples!

```{r generate}
#| echo: true
#| eval: false

hbr_maples %>% 
  specify(response = stem_dry_mass,
          explanatory = stem_length) %>% 
  hypothesize(null = "independence") %>% 
  generate(reps = 1000, type = "permute")
```

. . .

</br>

:::::: columns
::: {.column width="45%"}
`reps` -- the number of resamples you want to generate
:::

::: {.column width="5%"}
:::

::: {.column width="45%"}
`"permute"` -- the method that should be used to generate the new samples
:::
::::::

## Step 4: Calculate your statistics!

```{r calculate}
#| eval: false
#| echo: true

hbr_maples %>% 
  specify(response = stem_dry_mass,
          explanatory = stem_length) %>% 
  hypothesize(null = "independence") %>% 
  generate(reps = 1000, type = "permute") %>% 
  calculate(stat = "slope") 
```

## Your turn!

Why is the `hypothesize()` function used to make a null distribution but not for a bootstrap distribution?

</br>

What does the `null = "independence"` input in `hypothesize()` mean? What is it assuming about the variables declared in the `specify()` step?

## The final product

```{r null-dist}
#| out-width: 70%
#| echo: true
visualise(null_dist) + 
  labs(x = "Permuted Slope Statistic")
```

## Is our observed statistic unlikely if the null hypothesis was true?

```{r}
#| label: obs-slope

obs_slope <- hbr_maples %>% 
  specify(response = stem_dry_mass,
          explanatory = stem_length) %>% 
  calculate(stat = "slope") 
```

```{r}
#| echo: true
#| label: null-dist-with-obs-slope

visualise(null_dist) +
  xlim(c(-0.0011, 0.0011)) +
  shade_p_value(obs_stat = obs_slope, 
                direction = "two-sided") +
  labs(x = "Permuted Slope Statistic")
```

## Two-sided Alternative

If our alternative hypothesis is two-sided, what is missing from the plot?

```{r}
#| echo: false
#| label: null-dist-with-obs-slope-2
#| fig-align: center

visualise(null_dist) +
  xlim(c(-0.0011, 0.0011)) +
  shade_p_value(obs_stat = obs_slope, 
                direction = "two-sided") +
  labs(x = "Permuted Slope Statistic")
```

## The p-value is...

```{r}
#| echo: true
#| label: p-value
#| message: true
#| warning: true
get_p_value(null_dist, 
            obs_stat = obs_slope, 
            direction = "two-sided") 
```

. . .

</br>

::: {style="font-size: 1.5em; color: #ed8402;"}
Why did we get a warning?
:::

## How do we interpret a p-value?

. . .

Need:

-   probability of what we saw in the data
-   assuming the null hypothesis is true

. . .

> The probability of observing a slope statistic (for the relationship between stem length and stem dry mass) as or more extreme than what was observed is less than 1 in 1000, if there was no relationship between a sugar maple's stem length and stem dry mass.

## Decision versus Conclusion

::: columns
::: {.column width="47%"}
[**Decision**]{style="font-size: 1.5em;"}

::: {.fragment}
At an $\alpha$ of 0.05 and a p-value of less than 0.001, we would reject $H_0$.
:::
:::

::: {.column width="5%"}
:::

::: {.column width="47%"}
::: {.fragment}
[**Conclusion**]{style="font-size: 1.5em;"}

We conclude that there is a linear relationship between the stem length and stem
dry mass for sugar maples in the Hubbard Brook Experimental Forest. 
:::
:::
:::

<!-- add slide about why we choose 0.05 versus 0.01 -->

# Lab 7

## Today's Data

::: columns
::: {.column width="65%"}
::: small
> "One of the best-known patterns in biogeography is Bergmann‚Äôs rule. It
> predicts that organisms at higher latitudes are larger than ones at lower
> latitudes. Many organisms follow Bergmann‚Äôs rule, including insects, birds, 
> snakes, marine invertebrates, and > terrestrial and marine mammals. What
> drives Bergmann‚Äôs rule? Bergmann originally hypothesized that the organisms
> he studied, birds, were larger in the colder, higher latitudes due to
> heat-conservation. But the heat-conservation hypothesis relies on internal
> regulation of body temperature and therefore 
> [does not apply to ectotherms]{.underline}, some of which also follow
> Bergmann‚Äôs rule."
:::

:::

::: {.column width="5%"}
:::

::: {.column width="30%"}
![](images/fiddler-crab.jpg){fig-alt="A fiddler crab on wet, muddy ground. The crab has one large, pale claw and one much smaller claw, with a shiny carapace and stalked eyes."}
:::
:::

## Research Question

</br> </br>

::: centered
> What is the relationship between a Fiddler Crab's body size (carapace width)
> and the latitude in which it lives?
:::

## Accessing Lab 7

::: {.midi}
**Step 1:** Both members of your group need to join your **group** workspace 
(link posted in the Announcements of your group)
:::

. . .

::: {.small}
::: {.callout-note}
# Roles
You will be trading off roles in the middle of the lab! One person will do the 
hypothesis test coding and one person will do the confidence interval coding! 
:::
:::

. . .

::: {.midi}
**Step 2:** One member of your group needs to [follow these instructions to copy the Lab 7 project into your group's workspace](https://scribehow.com/shared/Copying_the_Lab_to_Your_Group_Workspace__Q3uBlpp_TBWRZzVJmCjbsA)
:::

. . .

::: {.midi}
**Step 3:** Both members open the Lab 7 assignment in your group workspace!
:::

. . .

::: {.midi}
**Step 4:** Follow the [final instructions](https://scribehow.com/shared/Enabling_Collaborative_Editing_in_Posit_Cloud__ylk0d72IQfipwem_lfynlw) to activate collaborative editing in the document. 
:::

::: {.small}
::: {.callout-important}
# Source Editor

You need to be in the source editor (not the pretty one) to use collaborative editing! 
:::
:::

