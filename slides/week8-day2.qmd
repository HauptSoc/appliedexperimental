---
title: "ðŸ”¬ Simulation-Based Methods versus Theory-Based Methods"
format: 
  revealjs:
    theme: style.scss
editor: visual
---

```{r set-up}
library(tidyverse)
library(infer)
library(moderndive)
library(lterdatasampler)
library(palmerpenguins)

my_theme <- theme(axis.title.x = element_text(size = 18), 
                  axis.title.y = element_text(size = 18), 
                  axis.text.x = element_text(size = 12), 
                  axis.text.y = element_text(size = 12))

obs_slope <- evals %>% 
  specify(response = score, 
          explanatory = bty_avg) %>% 
  calculate(stat = "slope")
```

# Lab 7 Recap

## Common Mistakes

**Question 8** (Interpret Confidence Interval):

-   Did not include population in interpretation
-   Stated interval was about crabs not marshes

</br>

**Question 11** (Bootstrap Assumptions):

-   Did not talk about the sample of marshes
-   Stated population was crabs

# Statistical Critique 2

## First Steps

1.  Open the directions!
2.  Copy the Statistical Critique template on Posit Cloud
3.  Copy-and-paste code from your Midterm Project
4.  Copy-and-paste your justification for why you chose the model you chose

## Next Steps

4.  Fit the most complex model
5.  Obtain an ANOVA table of your model
6.  Use the p-values in the ANOVA table to decide what model is best

## What is the "most complex" model?

**For 1 numerical & 1 categorical explanatory variables**

-   Fit the **different slopes** (interaction) model

```{r}
#| label: diff-slopes-fit
#| echo: true
#| code-line-numbers: false

species_lm <- lm(bill_length_mm ~ bill_depth_mm * species, 
                  data = penguins)
```

. . .

</br>

**For 2 numerical explanatory variables**

-   Fit the model with **both** variables included:

```{r}
#| label: mlr-fit
#| echo: true
#| code-line-numbers: false

bill_lm <- lm(bill_length_mm ~ body_mass_g + bill_depth_mm, 
                  data = penguins)
```

## How do I know what model is "best" from the ANOVA table?

**For 1 numerical & 1 categorical explanatory variables**

-   Look at the interaction line (e.g., `bill_depth_mm:species`), it is testing if the slopes are different!

```{r}
#| label: diff-slopes-anova
#| echo: true
#| eval: false
#| code-line-numbers: false

anova(species_lm)
```

```{r}
anova(species_lm) %>% 
  broom::tidy() %>% 
  gt::gt()
```

## 

::: {style="font-size: 2em; color: #000000;"}
`bill_depth_mm:species`: With a p-value of 0.0000189, I would conclude there is evidence that the slopes are different!
:::

## How do I know what model is "best" from the ANOVA table?

**For 2 numerical explanatory variables**

-   Look at the p-value for each variable, it is testing if that variable has a relationship with the response (conditional on the other variable being in the model)!

```{r}
#| label: mlr-anova
#| echo: true
#| eval: false
#| code-line-numbers: false

anova(bill_lm)
```

```{r}
anova(bill_lm) %>% 
  broom::tidy() %>% 
  gt::gt()
```

## 

::: {style="font-size: 1.25em; color: #000000;"}
`body_mass_g`: With a p-value of approximately 0, I would conclude there is a relationship between body mass and bill length (after accounting for bill depth)!
:::

</br>

::: {style="font-size: 1.25em; color: #000000;"}
`bill_depth_mm`: With a p-value of 0.234, I would conclude there is not a relationship between bill depth and bill length (after accounting for body mass)!
:::

# 15-minute Work Session

# What did we do on Tuesday?

## 

::: {style="font-size: 2em; color: #000000;"}
We carried out a hypothesis test!
:::

::: columns
::: {.column width="35%"}
$$H_0: \beta_1 = 0$$

$$H_A: \beta_1 \neq 0$$
:::

::: {.column width="5%"}
:::

::: {.column width="60%"}
```{r evals-slr}
#| message: false
#| fig-align: center

ggplot(data = evals, 
       mapping = aes(x = bty_avg, y = score)) +
  geom_jitter() + 
  geom_smooth(method = "lm") +
  labs(x = "Average Beauty Score", 
       y = "Course Evaluation Score") +
  my_theme
```
:::
:::

::: {style="font-size: 1em; color: #ed8402;"}
What do these hypotheses mean *in words*?
:::

## 

::: {style="font-size: 2em; color: #000000;"}
By creating a permutation distribution!
:::

```{r evals-permute}
#| echo: true
null_dist <- evals %>% 
  specify(response = score, 
          explanatory = bty_avg) %>% 
  hypothesise(null = "independence") %>% 
  generate(reps = 1000, type = "permute") %>% 
  calculate(stat = "slope")
```

## 

::: {style="font-size: 2em; color: #000000;"}
And visualizing where our observed statistic fell on the distribution
:::

::: columns
::: {.column width="60%"}
```{r}
visualise(null_dist) +
  shade_p_value(obs_stat = obs_slope, direction = "two-sided") +
  labs(x = "Permuted Slope Statistic")
```
:::

::: {.column width="5%"}
:::

::: {.column width="35%"}
::: {style="font-size: 1.5em; color: #34605f;"}
What would you estimate the p-value to be?
:::
:::
:::

## 

::: {style="font-size: 2em; color: #000000;"}
And calculated the p-value
:::

```{r}
#| echo: true

get_p_value(null_dist, 
            obs_stat = obs_slope, 
            direction = "two-sided")
```

. . .

</br>

What would you decide for this hypothesis test? What conclusion would you reach about these hypotheses?

## 

::: {style="font-size: 2.5em; color: #000000;"}
How would this process have changed if we used theory-based methods instead?
:::

## 

::: {style="font-size: 2em; color: #000000;"}
Approximating the permutation distribution
:::

::: columns
::: {.column width="40%"}
A $t$-distribution can be a reasonable approximation for the permutation distribution if certain conditions are not violated.
:::

::: {.column width="5%"}
:::

::: {.column width="55%"}
```{r t-distribution}
plot(c(-5, 5),
     c(0, dnorm(0)),
      type = "n", 
     ylab = "", 
     xlab = "",
     axes = FALSE
     )

at <- seq(-10, 10, 2)
axis(1, at)
axis(1, at - 1, rep("", length(at)), tcl = -0.1)
abline(h = 0)
COL. <- openintro::fadeColor(openintro::IMSCOL["blue", "full"], c("FF", "89", "68", "4C", "33"))
COLt <- openintro::fadeColor(openintro::IMSCOL["blue", "full"], c("FF", "AA", "85", "60", "45"))
DF <- c("normal", 8, 4, 2, 1)
X <- seq(-10, 10, 0.02)
Y <- dnorm(X)
lines(X, Y, col = COL.[1])
for (i in 2:5) {
  Y <- dt(X, as.numeric(DF[i]))
  lines(X, Y, col = COL.[i], lwd = 1.5)
}
legend(2.5, 0.4,
  legend = c(
    DF[1],
    paste("t, df = ", DF[2:5], sep = "")
  ),
  col = COL.,
  text.col = COLt,
  lty = rep(1, 5),
  lwd = 1.5
)

```
:::
:::

## 

::: {style="font-size: 2em; color: #000000;"}
What about the observed statistic?
:::

::: panel-tabset
## Before

```{r}
#| echo: true
#| label: obs-slope-code

obs_slope <- evals %>% 
  specify(response = score, 
          explanatory = bty_avg) %>% 
  calculate(stat = "slope")
```

```{r}
#| label: obs-slope
pull(obs_slope)
```

## Now

```{r}
#| echo: true
#| eval: false
#| label: obs-t-code

evals_lm <- lm(score ~ bty_avg,
               data = evals)

get_regression_table(evals_lm)
```

```{r}
#| label: obs-t

evals_lm <- lm(score ~ bty_avg,
               data = evals)

coef_table <- get_regression_table(evals_lm)

t_stat <- filter(coef_table, term == "bty_avg") %>% 
  select(statistic)

slope_stat <- filter(coef_table, term == "bty_avg") %>% 
  select(estimate)

t_stat
```
:::

## 

::: {style="font-size: 2em; color: #000000;"}
How did R calculate the $t$-statistic?
:::

::: panel-tabset
## Step 1: SE

::: columns
::: {.column width="40%"}
$SE_{b_1} = \frac{\frac{s_y}{s_x} \cdot \sqrt{1 - r^2}}{\sqrt{n - 2}}$
:::

::: {.column width="5%"}
:::

::: {.column width="55%"}
```{r}
se_num <- ( sd(evals$score) / sd(evals$bty_avg) ) * 
  sqrt(
    1 - cor(evals$score, evals$bty_avg)
    ) 

se_denom <- sqrt(nrow(evals) - 2)

se <- se_num / se_denom

se
```
:::
:::

## Step 2: t-statistic

$t = \frac{b_1}{SE_{b_1}} = \frac{`r slope_stat`}{`r se`} = `r slope_stat / se`$

## Proof!

```{r}
get_regression_table(evals_lm) %>% 
  gt::gt()
```
:::

## 

::: {style="font-size: 2em; color: #000000;"}
How does R calculate the p-value?
:::

. . .

```{r}
#| fig-align: center
#| out-width: 50%

ggplot(data = tibble(x = c(-5, 5)), 
       mapping = aes(x)) +
  stat_function(fun = dt, 
                args = list(df = nrow(evals) - 2), 
                color = "blue", 
                linewidth = 1.5) +
  ylab("") +
  scale_y_continuous(breaks = NULL) +
  geom_vline(xintercept = pull(t_stat), color = "red", linewidth = 1.5)

```

## 

::: {style="font-size: 3.5em; color: #34605f;"}
Did we get similar results between these methods?
:::

## 

::: {style="font-size: 2em; color: #000000;"}
Why not always use theoretical methods?
:::

. . .

::: columns
::: {.column width="45%"}
Theory-based methods only hold if the sampling distribution is normally shaped.
:::

::: {.column width="5%"}
:::

::: {.column width="45%"}
::: fragment
The normality of a sampling distribution depends **heavily** on model conditions.
:::
:::
:::

## 

::: {style="font-size: 2em; color: #000000;"}
What are these "conditions"?
:::

. . .

::: columns
::: {.column width="40%"}
For linear regression we are assuming...
:::

::: {.column width="5%"}
:::

::: {.column width="55%"}
**L**inear relationship between $x$ and $y$

</br>

**I**ndepdent observations

</br>

**N**ormality of residuals

</br>

**E**qual variance of residuals
:::
:::

## 

::: {style="font-size: 2em; color: #000000;"}
**L**inear relationship between $x$ and $y$
:::

```{r}
#| fig-align: center

and_vertebrates %>%
  filter(species != "Cascade torrent salamander") %>% 
  ggplot(mapping = aes(x = length_1_mm, 
                       y = weight_g, 
                       color = species)) +
  geom_point() + 
  labs(x = "Length (mm)", 
       y = "Weight (g)") +
  my_theme
```

. . .

**What should we do?**

## 

::: {style="font-size: 2em; color: #000000;"}
Variable transformation!
:::

```{r transform}
#| fig-align: center

and_vertebrates %>%
  filter(species != "Cascade torrent salamander") %>% 
  ggplot(mapping = aes(x = length_1_mm, 
                       y = weight_g, 
                       color = species)) +
  geom_jitter(alpha = 0.5) + 
  labs(x = "Log Transformed Length (mm)", 
       y = "Log Transformed Weight (g)", 
       color = "Species") +
  scale_x_log10() +
  scale_y_log10() +
  my_theme
```

## 

::: {style="font-size: 2em; color: #000000;"}
**I**ndependence of observations
:::

::: columns
::: {.column width="40%"}
The `evals` dataset contains `r nrow(evals)` observations on `r distinct(evals, prof_ID) %>% nrow()` professors. Meaning, professors have **multiple** observations.

</br>

*What can we do?*
:::

::: {.column width="5%"}
:::

::: {.column width="55%"}
::: fragment
**Best** -- use a random effects model

**Reasonable** -- collapse the multiple scores into a single score
:::
:::
:::

## 

::: {style="font-size: 2em; color: #000000;"}
**N**ormality of residuals
:::

```{r non-normal}

fish <- and_vertebrates %>%
  filter(!species %in% c("Cascade torrent salamander", "Coastal giant salamander")) 

curved_lm <- lm(weight_g ~ length_1_mm, data = fish)

get_regression_points(curved_lm) %>% 
  ggplot(mapping = aes(x = residual)) + 
  geom_histogram() + 
  labs(x = "Residual") +
  my_theme
```

. . .

**What should we do?**

## 

::: {style="font-size: 2em; color: #000000;"}
Variable transformation!
:::

```{r normal}

fish <- and_vertebrates %>%
  filter(!species %in% c("Cascade torrent salamander", "Coastal giant salamander"))

not_curved_lm <- lm(log(weight_g) ~ log(length_1_mm), data = fish)

broom::augment(not_curved_lm) %>% 
  mutate(.resid = `log(weight_g)` - `.fitted`) %>% 
  ggplot(mapping = aes(x = .resid)) + 
  geom_histogram(binwidth = 0.1) + 
  labs(x = "Residual") +
  xlim(c(-0.5, 0.5)) +
  my_theme
```

## 

::: {style="font-size: 2em; color: #000000;"}
**E**qual variance of residuals
:::

```{r non-constant-variance}
#| fig-align: center

ggplot(data = hbr_maples, 
       mapping = aes(x = stem_length, y = stem_dry_mass)
       ) +
  geom_point() +
  geom_smooth(method = "lm") +
  labs(
    x = "Stem Length (mm)",
    y = "Stem Dry Mass (g)"
    ) +
  theme_minimal() + 
  my_theme
```

. . .

**What should we do?**

## 

::: {style="font-size: 2em; color: #000000;"}
Variable transformation!
:::

```{r}
ggplot(data = hbr_maples, 
       mapping = aes(x = stem_length, y = stem_dry_mass)
       ) +
  geom_point() +
  geom_smooth(method = "lm") +
  labs(
    x = "Stem Length (mm)",
    y = "Log Transformed Stem Dry Mass (g)"
  ) +
  theme_minimal() + 
  scale_y_log10() +
  my_theme
```

## 

::: {style="font-size: 2em; color: #000000;"}
Are these conditions required for **both** methods?
:::

. . .

::: columns
::: {.column width="40%"}
::: {style="font-size: 1.5em; color: #34605f;"}
Simulation-based Methods
:::

::: {style="font-size: 0.75em; color: #000000;"}
-   Linearity of Relationship

-   Independence of Observations

-   Equal Variance of Residuals
:::
:::

::: {.column width="5%"}
:::

::: {.column width="45%"}
::: {style="font-size: 1.5em; color: #34605f;"}
Theory-based Methods
:::

::: {style="font-size: 0.75em; color: #000000;"}
-   Linearity of Relationship
-   Independence of Observations
:::

::: {style="font-size: 0.75em; color: #ed8402;"}
-   Normality of Residuals
:::

::: {style="font-size: 0.75em; color: #000000;"}
-   Equal Variance of Residuals
:::
:::
:::

## 

::: {style="font-size: 2em; color: #000000;"}
What happens if the conditions are violated?
:::

. . .

In general, when the conditions associated with these methods are violated, the permutation and $t$-distributions will [underestimate]{.underline} the true standard error of the sampling distribution.

. . .

-   Our p-values will be **too** small!
-   Our confidence intervals will be **too** narrow!
-   We will make more Type I errors than we expect!

# Lab 8

<!-- Overview of what they are exploring -->
