---
title: "ðŸ”¬ Simulation-Based Methods versus Theory-Based Methods"
format: 
  revealjs:
    theme: style.scss
editor: visual
---

```{r set-up}
library(tidyverse)
library(infer)
library(moderndive)
library(lterdatasampler)
library(palmerpenguins)

my_theme <- theme(axis.title.x = element_text(size = 18), 
                  axis.title.y = element_text(size = 18), 
                  axis.text.x = element_text(size = 12), 
                  axis.text.y = element_text(size = 12))

obs_slope <- evals %>% 
  specify(response = score, 
          explanatory = bty_avg) %>% 
  calculate(stat = "slope")
```

# Lab 7 Recap

## Common Mistakes

**Question 8** (Interpret Confidence Interval):

-   Did not include population in interpretation
-   Stated interval was about crabs not marshes

</br>

**Question 11** (Bootstrap Assumptions):

-   Did not talk about the sample of marshes
-   Stated population was crabs

# Statistical Critique 2

## First Steps

1.  Open the directions!
2.  Copy the Statistical Critique template on Posit Cloud
3.  Copy-and-paste code from your Midterm Project
4.  Copy-and-paste your justification for why you chose the model you chose

## Next Steps

4.  Fit the most complex model
5.  Obtain an ANOVA table of your model
6.  Use the p-values in the ANOVA table to decide what model is best

## What is the "most complex" model?

**For 1 numerical & 1 categorical explanatory variables**

-   Fit the **different slopes** (interaction) model

```{r}
#| label: diff-slopes-fit
#| echo: true
#| code-line-numbers: false

species_lm <- lm(bill_length_mm ~ bill_depth_mm * species, 
                  data = penguins)
```

. . .

</br>

**For 2 numerical explanatory variables**

-   Fit the model with **both** variables included:

```{r}
#| label: mlr-fit
#| echo: true
#| code-line-numbers: false

bill_lm <- lm(bill_length_mm ~ body_mass_g + bill_depth_mm, 
                  data = penguins)
```

## How do I know what model is "best" from the ANOVA table?

**For 1 numerical & 1 categorical explanatory variables**

-   Look at the interaction line (e.g., `bill_depth_mm:species`), it is testing if the slopes are different!

```{r}
#| label: diff-slopes-anova
#| echo: true
#| eval: false
#| code-line-numbers: false

anova(species_lm)
```

```{r}
anova(species_lm) %>% 
  broom::tidy() %>% 
  gt::gt()
```

## 

::: {style="font-size: 2em; color: #000000;"}
`bill_depth_mm:species`: With a p-value of 0.0000189, I would conclude there is evidence that the slopes are different!
:::

## How do I know what model is "best" from the ANOVA table?

**For 2 numerical explanatory variables**

-   Look at the p-value for each variable, it is testing if that variable has a relationship with the response (conditional on the other variable being in the model)!

```{r}
#| label: mlr-anova
#| echo: true
#| eval: false
#| code-line-numbers: false

anova(bill_lm)
```

```{r}
anova(bill_lm) %>% 
  broom::tidy() %>% 
  gt::gt()
```

## 

::: {style="font-size: 1.25em; color: #000000;"}
`body_mass_g`: With a p-value of approximately 0, I would conclude there is a relationship between body mass and bill length (after accounting for bill depth)!
:::

</br>

::: {style="font-size: 1.25em; color: #000000;"}
`bill_depth_mm`: With a p-value of 0.234, I would conclude there is not a relationship between bill depth and bill length (after accounting for body mass)!
:::

# Last week we covered confidence intervals, this week we're learning more about hypothesis tests.

## Testing for a Population Slope ($\beta_1$)

::: columns
::: {.column width="35%"}
$$H_0: \beta_1 = 0$$

$$H_A: \beta_1 \neq 0$$
:::

::: {.column width="5%"}
:::

::: {.column width="60%"}
```{r evals-slr}
#| message: false
#| fig-align: center

ggplot(data = evals, 
       mapping = aes(x = bty_avg, y = score)) +
  geom_jitter() + 
  geom_smooth(method = "lm") +
  labs(x = "Average Beauty Score", 
       y = "Course Evaluation Score") +
  my_theme
```
:::
:::

. . .

::: {style="font-size: 1em; color: #ed8402;"}
What do these hypotheses mean *in words*?
:::

## What do you think?

::: columns
::: {.column width="50%"}
$\widehat{score} = 3.88 + 0.066 \times \text{bty_avg}$
:::

::: {.column width="5%"}
:::

::: {.column width="45%"}
```{r}
#| message: false
#| fig-align: center

ggplot(data = evals, 
       mapping = aes(x = bty_avg, y = score)) +
  geom_jitter() + 
  geom_smooth(method = "lm") +
  labs(x = "Average Beauty Score", 
       y = "Course Evaluation Score") +
  my_theme
```
:::
:::

. . .

::: {style="font-size: 1.5em; color: #b76352;"}
Will we reject $H_0$?
:::

# How will we decide?

# How will we decide?

:::{.midi}
by generating statistics that could have happened if $H_0$ was true and comparing our observed statistic to these statistics to see how unusual it is
:::

## If $H_0$ was true then...

</br> 

$\beta_1$ = 0 

</br> 

which means...

# How do we generate statistics that could have happened if $H_0$ was true?

## One possible shuffle

::: columns
::: {.column width="40%"}
```{r}
#| label: shuffle-scores
#| echo: false
#| cache: true

evals_shuffle <- evals %>% 
  select(score, bty_avg) %>% 
  mutate(shuffled_score = sample(score, 
                                size = nrow(evals), 
                                replace = FALSE)
        )

evals_shuffle %>% 
  slice_sample(n = 25) %>% 
  gt::gt()
```
:::

::: {.column width="5%"}
:::

::: {.column width="55%"}
:::{.fragment}
Which results in a slope statistic of...

```{r}
lm(score ~ bty_avg, data = evals_shuffle) %>% 
  broom::tidy() %>% 
  filter(term == "bty_avg") %>% 
  pull(estimate)
```

:::
:::
:::

# But that's just **one** statistic!

# But that's just **one** statistic!

We want a sampling distribution of **lots** of statistics that could have happened if $H_0$ was true!

## Lots of statistics that could have happened if $H_0$ was true

```{r}
#| label: evals-permute
#| cache: true

null_dist <- evals %>% 
  specify(response = score, 
          explanatory = bty_avg) %>% 
  hypothesise(null = "independence") %>% 
  generate(reps = 1000, type = "permute") %>% 
  calculate(stat = "slope")

visualise(null_dist) +
  labs(x = "Slope Statistic", 
       title = "")
```

## Where does our observed statistic fall on this distribution?

```{r}
#| label: null-dist

visualise(null_dist) +
  labs(x = "Slope Statistic", 
       title = "") +
  xlim(-0.08, 0.08) +
  scale_x_continuous(breaks = seq(-0.08, 0.08, by = 0.01))
```

## Is our observed statistic *likely* to happen if the null was true?

. . .

If it is unlikely to happen, then we should reject $H_0$! 

Why???

. . .

The probability of observing a statistic as or more extreme than 0.0666 is approximately 0%. 

# What conclusion would you reach about the relationship between professors' evaluation scores and their attractiveness?

# The conclusion we reached depends on our p-value being reliable. 

# The conclusion we reached depends on our p-value being reliable. 

How can we know if our p-value is reliable?

## Model Conditions

For our p-value to be trustworthy, we need to know that the conditions of our model are not violated. 

. . .

::: columns
::: {.column width="40%"}
For linear regression we are assuming...
:::

::: {.column width="5%"}
:::

::: {.column width="55%"}
**L**inear relationship between $x$ and $y$

</br>

**I**ndepdent observations

</br>

**N**ormality of residuals

</br>

**E**qual variance of residuals
:::
:::

## What happens if the conditions are violated?

In general, when the conditions associated with these methods are violated, we will [underestimate]{.underline} the true standard error (spread) of the sampling distribution.

. . .

-   Our p-values will be **too** small!
-   Our confidence intervals will be **too** narrow!
-   We will make more Type I errors than we expect!

## 

::: {style="font-size: 2em; color: #000000;"}
**L**inear relationship between $x$ and $y$
:::

```{r}
#| fig-align: center

and_vertebrates %>%
  filter(species != "Cascade torrent salamander") %>% 
  ggplot(mapping = aes(x = length_1_mm, 
                       y = weight_g, 
                       color = species)) +
  geom_point() + 
  labs(x = "Length (mm)", 
       y = "Weight (g)") +
  my_theme
```

. . .

**What should we do?**

## 

::: {style="font-size: 2em; color: #000000;"}
Variable transformation!
:::

```{r transform}
#| fig-align: center

and_vertebrates %>%
  filter(species != "Cascade torrent salamander") %>% 
  ggplot(mapping = aes(x = length_1_mm, 
                       y = weight_g, 
                       color = species)) +
  geom_jitter(alpha = 0.5) + 
  labs(x = "Log Transformed Length (mm)", 
       y = "Log Transformed Weight (g)", 
       color = "Species") +
  scale_x_log10() +
  scale_y_log10() +
  my_theme
```

## 

::: {style="font-size: 2em; color: #000000;"}
**I**ndependence of observations
:::

::: columns
::: {.column width="40%"}
The `evals` dataset contains `r nrow(evals)` observations on `r distinct(evals, prof_ID) %>% nrow()` professors. Meaning, professors have **multiple** observations.

</br>

*What can we do?*
:::

::: {.column width="5%"}
:::

::: {.column width="55%"}
::: fragment
**Best** -- use a random effects model

**Reasonable** -- collapse the multiple scores into a single score
:::
:::
:::

## 

::: {style="font-size: 2em; color: #000000;"}
**N**ormality of residuals
:::

```{r non-normal}

fish <- and_vertebrates %>%
  filter(!species %in% c("Cascade torrent salamander", "Coastal giant salamander")) 

curved_lm <- lm(weight_g ~ length_1_mm, data = fish)

get_regression_points(curved_lm) %>% 
  ggplot(mapping = aes(x = residual)) + 
  geom_histogram() + 
  labs(x = "Residual") +
  my_theme
```

. . .

**What should we do?**

## 

::: {style="font-size: 2em; color: #000000;"}
Variable transformation!
:::

```{r normal}

fish <- and_vertebrates %>%
  filter(!species %in% c("Cascade torrent salamander", "Coastal giant salamander"))

not_curved_lm <- lm(log(weight_g) ~ log(length_1_mm), data = fish)

broom::augment(not_curved_lm) %>% 
  mutate(.resid = `log(weight_g)` - `.fitted`) %>% 
  ggplot(mapping = aes(x = .resid)) + 
  geom_histogram(binwidth = 0.1) + 
  labs(x = "Residual") +
  xlim(c(-0.5, 0.5)) +
  my_theme
```

## 

::: {style="font-size: 2em; color: #000000;"}
**E**qual variance of residuals
:::

```{r non-constant-variance}
#| fig-align: center

ggplot(data = hbr_maples, 
       mapping = aes(x = stem_length, y = stem_dry_mass)
       ) +
  geom_point() +
  geom_smooth(method = "lm") +
  labs(
    x = "Stem Length (mm)",
    y = "Stem Dry Mass (g)"
    ) +
  theme_minimal() + 
  my_theme
```

. . .

**What should we do?**

## 

::: {style="font-size: 2em; color: #000000;"}
Variable transformation!
:::

```{r}
ggplot(data = hbr_maples, 
       mapping = aes(x = stem_length, y = stem_dry_mass)
       ) +
  geom_point() +
  geom_smooth(method = "lm") +
  labs(
    x = "Stem Length (mm)",
    y = "Log Transformed Stem Dry Mass (g)"
  ) +
  theme_minimal() + 
  scale_y_log10() +
  my_theme
```


##

## 

::: {style="font-size: 2em; color: #000000;"}
Approximating the permutation distribution
:::

::: columns
::: {.column width="40%"}
A $t$-distribution can be a reasonable approximation for the permutation distribution if certain conditions are not violated.
:::

::: {.column width="5%"}
:::

::: {.column width="55%"}
```{r t-distribution}
plot(c(-5, 5),
     c(0, dnorm(0)),
      type = "n", 
     ylab = "", 
     xlab = "",
     axes = FALSE
     )

at <- seq(-10, 10, 2)
axis(1, at)
axis(1, at - 1, rep("", length(at)), tcl = -0.1)
abline(h = 0)
COL. <- openintro::fadeColor(openintro::IMSCOL["blue", "full"], c("FF", "89", "68", "4C", "33"))
COLt <- openintro::fadeColor(openintro::IMSCOL["blue", "full"], c("FF", "AA", "85", "60", "45"))
DF <- c("normal", 8, 4, 2, 1)
X <- seq(-10, 10, 0.02)
Y <- dnorm(X)
lines(X, Y, col = COL.[1])
for (i in 2:5) {
  Y <- dt(X, as.numeric(DF[i]))
  lines(X, Y, col = COL.[i], lwd = 1.5)
}
legend(2.5, 0.4,
  legend = c(
    DF[1],
    paste("t, df = ", DF[2:5], sep = "")
  ),
  col = COL.,
  text.col = COLt,
  lty = rep(1, 5),
  lwd = 1.5
)

```
:::
:::

## 

::: {style="font-size: 2em; color: #000000;"}
What about the observed statistic?
:::

::: panel-tabset
## Before

```{r}
#| echo: true
#| label: obs-slope-code

obs_slope <- evals %>% 
  specify(response = score, 
          explanatory = bty_avg) %>% 
  calculate(stat = "slope")
```

```{r}
#| label: obs-slope
pull(obs_slope)
```

## Now

```{r}
#| echo: true
#| eval: false
#| label: obs-t-code

evals_lm <- lm(score ~ bty_avg,
               data = evals)

get_regression_table(evals_lm)
```

```{r}
#| label: obs-t

evals_lm <- lm(score ~ bty_avg,
               data = evals)

coef_table <- get_regression_table(evals_lm)

t_stat <- filter(coef_table, term == "bty_avg") %>% 
  select(statistic)

slope_stat <- filter(coef_table, term == "bty_avg") %>% 
  select(estimate)

t_stat
```
:::

## 

::: {style="font-size: 2em; color: #000000;"}
How did R calculate the $t$-statistic?
:::

::: panel-tabset
## Step 1: SE

::: columns
::: {.column width="40%"}
$SE_{b_1} = \frac{\frac{s_y}{s_x} \cdot \sqrt{1 - r^2}}{\sqrt{n - 2}}$
:::

::: {.column width="5%"}
:::

::: {.column width="55%"}
```{r}
se_num <- ( sd(evals$score) / sd(evals$bty_avg) ) * 
  sqrt(
    1 - cor(evals$score, evals$bty_avg)
    ) 

se_denom <- sqrt(nrow(evals) - 2)

se <- se_num / se_denom

se
```
:::
:::

## Step 2: t-statistic

$t = \frac{b_1}{SE_{b_1}} = \frac{`r slope_stat`}{`r se`} = `r slope_stat / se`$

## Proof!

```{r}
get_regression_table(evals_lm) %>% 
  gt::gt()
```
:::

## 

::: {style="font-size: 2em; color: #000000;"}
How does R calculate the p-value?
:::

. . .

```{r}
#| fig-align: center
#| out-width: 50%

ggplot(data = tibble(x = c(-5, 5)), 
       mapping = aes(x)) +
  stat_function(fun = dt, 
                args = list(df = nrow(evals) - 2), 
                color = "blue", 
                linewidth = 1.5) +
  ylab("") +
  scale_y_continuous(breaks = NULL) +
  geom_vline(xintercept = pull(t_stat), color = "red", linewidth = 1.5)

```

## 

::: {style="font-size: 3.5em; color: #34605f;"}
Did we get similar results between these methods?
:::

## 

::: {style="font-size: 2em; color: #000000;"}
Why not always use theoretical methods?
:::

. . .

::: columns
::: {.column width="45%"}
Theory-based methods only hold if the sampling distribution is normally shaped.
:::

::: {.column width="5%"}
:::

::: {.column width="45%"}
::: fragment
The normality of a sampling distribution depends **heavily** on model conditions.
:::
:::
:::



# Lab 8

<!-- Overview of what they are exploring -->
