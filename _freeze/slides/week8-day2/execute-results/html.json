{
  "hash": "8ea9463d7b7bfd81944c1303a58386ac",
  "result": {
    "markdown": "---\ntitle: \"ðŸ”¬ Simulation-Based Methods versus Theory-Based Methods\"\nformat: \n  revealjs:\n    theme: dark\n    embed-resources: true\n    standalone: true\neditor: visual\n---\n\n::: {.cell}\n\n:::\n\n\n::: {style=\"font-size: 2em; color: #FFFFFF;\"}\nPlan for Revisions\n:::\n\n::: {style=\"font-size: 1.5em; color: #B6CADA;\"}\nRevisions will be accepted until Thursday, June 15.\n:::\n\n-   Week 8: **two** revisions will be accepted\n-   Week 9: **one** revision will be accepted\n-   Week 10: **one** revision will be accepted\n\n##\n\n::: {style=\"font-size: 2em; color: #FFFFFF;\"}\nPlan for Week 9\n:::\n\n::: incremental\n- Asynchronous class on Tuesday [**and**]{.underline} Thursday\n\n- Typical deadlines for reading (Tuesday) and tutorial (Thursday)\n\n- \"Checkpoints\" for Final Project incorporated throughout the week\n  * Introduction -- Due Wednesday\n  * Methods -- Due Friday\n  * Findings & Scope of Inference -- Due Sunday\n:::\n\n\n## \n\n::: {style=\"font-size: 2em; color: #FFFFFF;\"}\nSome advice on the your Final Project...\n:::\n\n\n## \n\n::: {style=\"font-size: 4em; color: #FFFFFF;\"}\nWhat did we do on Tuesday?\n:::\n\n## \n\n::: {style=\"font-size: 2em; color: #FFFFFF;\"}\nWe carried out a hypothesis test!\n:::\n\n::: columns\n::: {.column width=\"35%\"}\n$$H_0: \\beta_1 = 0$$\n\n$$H_A: \\beta_1 \\neq 0$$\n:::\n\n::: {.column width=\"5%\"}\n:::\n\n::: {.column width=\"60%\"}\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](week8-day2_files/figure-revealjs/evals-slr-1.png){fig-align='center' width=960}\n:::\n:::\n\n:::\n:::\n\n::: {style=\"font-size: 1em; color: #ed8402;\"}\nWhat do these hypotheses mean *in words*?\n:::\n\n## \n\n::: {style=\"font-size: 2em; color: #FFFFFF;\"}\nBy creating a permutation distribution!\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnull_dist <- evals %>% \n  specify(response = score, \n          explanatory = bty_avg) %>% \n  hypothesise(null = \"independence\") %>% \n  generate(reps = 1000, type = \"permute\") %>% \n  calculate(stat = \"slope\")\n```\n:::\n\n\n. . .\n\n</br>\n\n::: {style=\"font-size: 1.5em; color: #B6CADA;\"}\nWhat is happening in the `generate()` step?\n:::\n\n## \n\n::: {style=\"font-size: 2em; color: #FFFFFF;\"}\nAnd visualizing where our observed statistic fell on the distribution\n:::\n\n::: columns\n::: {.column width=\"60%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](week8-day2_files/figure-revealjs/unnamed-chunk-1-1.png){width=960}\n:::\n:::\n\n:::\n\n::: {.column width=\"5%\"}\n:::\n\n::: {.column width=\"35%\"}\n::: {style=\"font-size: 1.5em; color: #B6CADA;\"}\nWhat would you estimate the p-value to be?\n:::\n:::\n:::\n\n## \n\n::: {style=\"font-size: 2em; color: #FFFFFF;\"}\nAnd calculated the p-value\n:::\n\n::: columns\n::: {.column width=\"60%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nget_p_value(null_dist, \n            obs_stat = obs_slope, \n            direction = \"two-sided\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 Ã— 1\n  p_value\n    <dbl>\n1       0\n```\n:::\n:::\n\n:::\n\n::: {.column width=\"5%\"}\n:::\n\n::: {.column width=\"35%\"}\n::: {style=\"font-size: 1.5em; color: #B6CADA;\"}\n</br> </br> What would you decide for your hypothesis test?\n:::\n:::\n:::\n\n## \n\n::: {style=\"font-size: 2.5em; color: #FFFFFF;\"}\nHow would this process have changed if we used theory-based methods instead?\n:::\n\n## \n\n::: {style=\"font-size: 2em; color: #FFFFFF;\"}\nApproximating the permutation distribution\n:::\n\n::: columns\n::: {.column width=\"40%\"}\nA $t$-distribution can be a reasonable approximation for the permutation distribution if certain conditions are not violated.\n:::\n\n::: {.column width=\"5%\"}\n:::\n\n::: {.column width=\"55%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](week8-day2_files/figure-revealjs/t-distribution-1.png){width=960}\n:::\n:::\n\n:::\n:::\n\n## \n\n::: {style=\"font-size: 2em; color: #FFFFFF;\"}\nWhat about the observed statistic?\n:::\n\n::: panel-tabset\n## Before\n\n\n::: {.cell}\n\n```{.r .cell-code}\nobs_slope <- evals %>% \n  specify(response = score, \n          explanatory = bty_avg) %>% \n  calculate(stat = \"slope\")\n```\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\nResponse: score (numeric)\nExplanatory: bty_avg (numeric)\n# A tibble: 1 Ã— 1\n    stat\n   <dbl>\n1 0.0666\n```\n:::\n:::\n\n\n## Now\n\n\n::: {.cell}\n\n```{.r .cell-code}\nevals_lm <- lm(score ~ bty_avg,\n               data = evals)\n\nget_regression_table(evals_lm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 Ã— 7\n  term      estimate std_error statistic p_value lower_ci upper_ci\n  <chr>        <dbl>     <dbl>     <dbl>   <dbl>    <dbl>    <dbl>\n1 intercept    3.88      0.076     51.0        0    3.73     4.03 \n2 bty_avg      0.067     0.016      4.09       0    0.035    0.099\n```\n:::\n:::\n\n:::\n\n## \n\n::: {style=\"font-size: 2em; color: #FFFFFF;\"}\nHow did R calculate the $t$-statistic?\n:::\n\n::: panel-tabset\n## Step 1: SE\n\n::: columns\n::: {.column width=\"40%\"}\n$SE_{b_1} = \\frac{\\frac{s_y}{s_x} \\cdot \\sqrt{1 - r^2}}{\\sqrt{n - 2}}$\n:::\n\n::: {.column width=\"5%\"}\n:::\n\n::: {.column width=\"55%\"}\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.01495204\n```\n:::\n:::\n\n:::\n:::\n\n## Step 2: t-statistic\n\n::: columns\n::: {.column width=\"40%\"}\n$t = \\frac{b_1}{SE_{b_1}}$\n:::\n\n::: {.column width=\"5%\"}\n:::\n\n::: {.column width=\"55%\"}\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\nbty_avg \n4.45672 \n```\n:::\n:::\n\n:::\n:::\n\n## Proof!\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 Ã— 7\n  term      estimate std_error statistic p_value lower_ci upper_ci\n  <chr>        <dbl>     <dbl>     <dbl>   <dbl>    <dbl>    <dbl>\n1 intercept    3.88      0.076     51.0        0    3.73     4.03 \n2 bty_avg      0.067     0.016      4.09       0    0.035    0.099\n```\n:::\n:::\n\n:::\n\n## \n\n::: {style=\"font-size: 2em; color: #FFFFFF;\"}\nHow does R calculate the p-value?\n:::\n\n. . .\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](week8-day2_files/figure-revealjs/unnamed-chunk-7-1.png){fig-align='center' width=50%}\n:::\n:::\n\n\n. . .\n\n**How many degrees of freedom does this** $t$-distribution have?\n\n## \n\n::: {style=\"font-size: 3.5em; color: #B6CADA;\"}\nDid we get similar results between these methods?\n:::\n\n## \n\n::: {style=\"font-size: 2em; color: #FFFFFF;\"}\nWhy not always use theoretical methods?\n:::\n\n. . .\n\n::: columns\n::: {.column width=\"45%\"}\nTheory-based methods only hold if the sampling distribution is normally shaped.\n:::\n\n::: {.column width=\"5%\"}\n:::\n\n::: {.column width=\"45%\"}\nThe normality of a sampling distribution depends **heavily** on model conditions.\n:::\n:::\n\n## \n\n::: {style=\"font-size: 2em; color: #FFFFFF;\"}\nWhat are these \"conditions\"?\n:::\n\n. . .\n\n::: columns\n::: {.column width=\"40%\"}\nFor linear regression we are assuming...\n:::\n\n::: {.column width=\"5%\"}\n:::\n\n::: {.column width=\"55%\"}\n**L**inear relationship between $x$ and $y$\n\n</br>\n\n**I**ndepdent observations\n\n</br>\n\n**N**ormality of residuals\n\n</br>\n\n**E**qual variance of residuals\n:::\n:::\n\n## \n\n::: {style=\"font-size: 2em; color: #FFFFFF;\"}\n**L**inear relationship between $x$ and $y$\n:::\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](week8-day2_files/figure-revealjs/unnamed-chunk-8-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n. . .\n\n**What should we do?**\n\n## \n\n::: {style=\"font-size: 2em; color: #FFFFFF;\"}\nVariable transformation!\n:::\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](week8-day2_files/figure-revealjs/transform-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n## \n\n::: {style=\"font-size: 2em; color: #FFFFFF;\"}\n**I**ndependence of observations\n:::\n\n::: columns\n::: {.column width=\"40%\"}\nThe `evals` dataset contains 463 observations on 94 professors. Meaning, professors have **multiple** observations.\n\n</br>\n\n*What can we do?*\n:::\n\n::: {.column width=\"5%\"}\n:::\n\n::: {.column width=\"55%\"}\n**Best** -- use a random effects model\n\n**Reasonable** -- collapse the multiple scores into a single score\n:::\n:::\n\n## \n\n::: {style=\"font-size: 2em; color: #FFFFFF;\"}\n**N**ormality of residuals\n:::\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](week8-day2_files/figure-revealjs/non-normal-1.png){width=960}\n:::\n:::\n\n\n. . .\n\n**What should we do?**\n\n## \n\n::: {style=\"font-size: 2em; color: #FFFFFF;\"}\nVariable transformation!\n:::\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](week8-day2_files/figure-revealjs/normal-1.png){width=960}\n:::\n:::\n\n\n## \n\n::: {style=\"font-size: 2em; color: #FFFFFF;\"}\n**E**qual variance of residuals\n:::\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](week8-day2_files/figure-revealjs/non-constant-variance-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n. . .\n\n**What should we do?**\n\n## \n\n::: {style=\"font-size: 2em; color: #FFFFFF;\"}\nVariable transformation!\n:::\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](week8-day2_files/figure-revealjs/unnamed-chunk-9-1.png){width=960}\n:::\n:::\n\n\n## \n\n::: {style=\"font-size: 2em; color: #FFFFFF;\"}\nAre these conditions required for **both** methods?\n:::\n\n. . .\n\n::: columns\n::: {.column width=\"40%\"}\n::: {style=\"font-size: 1.5em; color: #B6CADA;\"}\nSimulation-based Methods\n:::\n\n::: {style=\"font-size: 0.75em; color: #FFFFFF;\"}\n-   Linearity of Relationship\n\n-   Independence of Observations\n\n-   Equal Variance of Residuals\n:::\n:::\n\n::: {.column width=\"5%\"}\n:::\n\n::: {.column width=\"45%\"}\n::: {style=\"font-size: 1.5em; color: #B6CADA;\"}\nTheory-based Methods\n:::\n\n::: {style=\"font-size: 0.75em; color: #FFFFFF;\"}\n-   Linearity of Relationship\n-   Independence of Observations\n:::\n\n::: {style=\"font-size: 0.75em; color: #B6CADA;\"}\n-   Normality of Residuals\n:::\n\n::: {style=\"font-size: 0.75em; color: #FFFFFF;\"}\n-   Equal Variance of Residuals\n:::\n:::\n:::\n\n## \n\n::: {style=\"font-size: 2em; color: #FFFFFF;\"}\nWhat happens if the conditions are violated?\n:::\n\n. . .\n\nIn general, when the conditions associated with these methods are violated, the permutation and $t$-distributions will underestimate the true standard error of the sampling distribution.\n",
    "supporting": [
      "week8-day2_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}