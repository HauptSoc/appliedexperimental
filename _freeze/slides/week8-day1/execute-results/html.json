{
  "hash": "a871d0b31aa388dac86a8c3d85b1cee6",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"ðŸ”¬ Simulation-Based Methods versus Theory-Based Methods\"\nformat: \n  revealjs:\n    theme: style.scss\neditor: source\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nâ”€â”€ Attaching core tidyverse packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse 2.0.0 â”€â”€\nâœ” dplyr     1.1.4     âœ” readr     2.1.5\nâœ” forcats   1.0.0     âœ” stringr   1.5.1\nâœ” ggplot2   3.5.1     âœ” tibble    3.2.1\nâœ” lubridate 1.9.3     âœ” tidyr     1.3.1\nâœ” purrr     1.0.4     \nâ”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse_conflicts() â”€â”€\nâœ– dplyr::filter() masks stats::filter()\nâœ– dplyr::lag()    masks stats::lag()\nâ„¹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(infer)\nlibrary(moderndive)\nlibrary(lterdatasampler)\nlibrary(palmerpenguins)\n\nmy_theme <- theme(axis.title.x = element_text(size = 18), \n                  axis.title.y = element_text(size = 18), \n                  axis.text.x = element_text(size = 12), \n                  axis.text.y = element_text(size = 12), \n                  legend.text = element_text(size = 12), \n                  legend.title = element_text(size = 18))\n\nobs_slope <- evals %>% \n  specify(response = score, \n          explanatory = bty_avg) %>% \n  calculate(stat = \"slope\")\n```\n:::\n\n\n\n\n\n# Lab 6 Recap\n\n## Common Mistakes\n\n</br>\n\n\n\n\n# The conclusions we reach depend on our p-value and confidence intervale being reliable.\n\n# The conclusions we reach depend on our p-value and confidence intervale being reliable.\n\nHow can we know if our p-value is reliable?\n\n## Model Conditions\n\nFor our p-value to be trustworthy, we need to know that the conditions of our model are not violated.\n\n. . .\n\n:::::: columns\n::: {.column width=\"40%\"}\nFor linear regression we are assuming...\n:::\n\n::: {.column width=\"5%\"}\n:::\n\n::: {.column width=\"55%\"}\n**L**inear relationship between $x$ and $y$\n\n</br>\n\n**I**ndependent observations\n\n</br>\n\n**N**ormality of residuals\n\n</br>\n\n**E**qual variance of residuals\n:::\n::::::\n\n## What happens if the conditions are violated?\n\nIn general, when the conditions associated with these methods are violated, we will [underestimate]{.underline} the true standard error (spread) of the sampling distribution.\n\n. . .\n\n-   Our p-values will be **too** small!\n-   Our confidence intervals will be **too** narrow!\n-   We will make more Type I errors than we expect!\n\n## \n\n::: {style=\"font-size: 2em; color: #000000;\"}\n**L**inear relationship between $x$ and $y$\n:::\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nand_vertebrates %>%\n  filter(species != \"Cascade torrent salamander\") %>% \n  ggplot(mapping = aes(x = length_1_mm, \n                       y = weight_g, \n                       color = species)) +\n  geom_point() + \n  labs(x = \"Length (mm)\", \n       y = \"Weight (g)\", \n       color = \"Species\") +\n  my_theme\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 13270 rows containing missing values or values outside the scale range\n(`geom_point()`).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](week8-day1_files/figure-html/unnamed-chunk-1-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n\n\n\n. . .\n\n***What should we do?***\n\n## \n\n::: {style=\"font-size: 2em; color: #000000;\"}\nVariable transformation!\n:::\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nand_vertebrates %>%\n  filter(species != \"Cascade torrent salamander\") %>% \n  ggplot(mapping = aes(x = length_1_mm, \n                       y = weight_g, \n                       color = species)) +\n  geom_jitter(alpha = 0.5) + \n  labs(x = \"Log Transformed Length (mm)\", \n       y = \"Log Transformed Weight (g)\", \n       color = \"Species\") +\n  scale_x_log10() +\n  scale_y_log10() +\n  my_theme\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 13270 rows containing missing values or values outside the scale range\n(`geom_point()`).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](week8-day1_files/figure-html/transform-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n\n\n\n## \n\n::: {style=\"font-size: 2em; color: #000000;\"}\n**I**ndependence of observations\n:::\n\n::::::: columns\n::: {.column width=\"40%\"}\nThe `evals` dataset contains 463 observations on 94 professors. Meaning, professors have **multiple** observations.\n\n</br>\n\n***What should we do?***\n:::\n\n::: {.column width=\"5%\"}\n:::\n\n:::: {.column width=\"55%\"}\n::: fragment\n**Best** -- use a random effects model\n\n**Reasonable** -- collapse the multiple scores into a single score\n:::\n::::\n:::::::\n\n## \n\n::: {style=\"font-size: 2em; color: #000000;\"}\n**E**qual variance of residuals\n:::\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(data = hbr_maples, \n       mapping = aes(x = stem_length, y = stem_dry_mass)\n       ) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  labs(\n    x = \"Stem Length (mm)\",\n    y = \"Stem Dry Mass (g)\"\n    ) +\n  theme_minimal() + \n  my_theme\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](week8-day1_files/figure-html/non-constant-variance-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n\n\n\n. . .\n\n***What should we do?***\n\n## \n\n::: {style=\"font-size: 2em; color: #000000;\"}\nVariable transformation!\n:::\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = hbr_maples, \n       mapping = aes(x = stem_length, y = stem_dry_mass)\n       ) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  labs(\n    x = \"Stem Length (mm)\",\n    y = \"Log Transformed Stem Dry Mass (g)\"\n  ) +\n  theme_minimal() + \n  scale_y_log10() +\n  my_theme\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](week8-day1_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n\n\n\n## \n\n::: {style=\"font-size: 2em; color: #000000;\"}\n**N**ormality of residuals\n:::\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfish <- and_vertebrates %>%\n  filter(!species %in% c(\"Cascade torrent salamander\", \"Coastal giant salamander\")) \n\ncurved_lm <- lm(weight_g ~ length_1_mm, data = fish)\n\nget_regression_points(curved_lm) %>% \n  ggplot(mapping = aes(x = residual)) + \n  geom_histogram() + \n  labs(x = \"Residual\") +\n  my_theme\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](week8-day1_files/figure-html/non-normal-1.png){width=672}\n:::\n:::\n\n\n\n\n\n. . .\n\n***What should we do?***\n\n## \n\n::: {style=\"font-size: 2em; color: #000000;\"}\nVariable transformation!\n:::\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfish <- and_vertebrates %>%\n  filter(!species %in% c(\"Cascade torrent salamander\", \"Coastal giant salamander\"))\n\nnot_curved_lm <- lm(log(weight_g) ~ log(length_1_mm), data = fish)\n\nbroom::augment(not_curved_lm) %>% \n  mutate(.resid = `log(weight_g)` - `.fitted`) %>% \n  ggplot(mapping = aes(x = .resid)) + \n  geom_histogram(binwidth = 0.1) + \n  labs(x = \"Residual\") +\n  xlim(c(-0.5, 0.5)) +\n  my_theme\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 73 rows containing non-finite outside the scale range\n(`stat_bin()`).\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](week8-day1_files/figure-html/normal-1.png){width=672}\n:::\n:::\n\n\n\n\n\n## What if we can't fix a condition being violated?\n\n. . .\n\n::::::: columns\n::: {.column width=\"45%\"}\nFor the **L**, **I**, and **E** conditions...\n\nwe need to ask for help!\n:::\n\n::: {.column width=\"5%\"}\n:::\n\n:::: {.column width=\"45%\"}\n::: fragment\nFor the **N** condition...\n\nwe need to use simulation instead of mathematical formulas to get our p-value and confidence interval.\n:::\n::::\n:::::::\n\n# Simulation-Based Methods versus Theory-Based Methods\n\n## Mathematical / Theory-based Methods\n\n::: incremental\n-   Are a \"simpler\" approach\n-   Use formulas instead of simulation to obtain standard error\n-   Use $t$-distribution to get p-value and confidence interval\n-   Require that the residuals are normally distributed\n:::\n\n## How does this look?\n\n:::: panel-tabset\n## Before\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"false\"}\nobs_slope <- evals %>% \n  specify(response = score, \n          explanatory = bty_avg) %>% \n  calculate(stat = \"slope\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npull(obs_slope)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   bty_avg \n0.06663704 \n```\n\n\n:::\n:::\n\n\n\n\n\n## Now\n\n::: smaller\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"false\"}\nevals_lm <- lm(score ~ bty_avg, data = evals)\n\nget_regression_table(evals_lm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 Ã— 7\n  term      estimate std_error statistic p_value lower_ci upper_ci\n  <chr>        <dbl>     <dbl>     <dbl>   <dbl>    <dbl>    <dbl>\n1 intercept    3.88      0.076     51.0        0    3.73     4.03 \n2 bty_avg      0.067     0.016      4.09       0    0.035    0.099\n```\n\n\n:::\n:::\n\n\n\n\n:::\n\n\n\n\n\n\n\n\n\n\n::::\n\n## \n\n::: {style=\"font-size: 2em; color: #000000;\"}\nHow did R calculate the $t$-statistic?\n:::\n\n::::::: panel-tabset\n## Step 1: SE\n\n:::::: columns\n::: {.column width=\"40%\"}\n$SE_{b_1} = \\frac{\\frac{s_y}{s_x} \\cdot \\sqrt{1 - r^2}}{\\sqrt{n - 2}}$\n:::\n\n::: {.column width=\"5%\"}\n:::\n\n::: {.column width=\"55%\"}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nse_num <- ( sd(evals$score) / sd(evals$bty_avg) ) * \n  sqrt(\n    1 - cor(evals$score, evals$bty_avg)\n    ) \n\nse_denom <- sqrt(nrow(evals) - 2)\n\nse <- se_num / se_denom\n\nse\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.01495204\n```\n\n\n:::\n:::\n\n\n\n\n:::\n::::::\n\n## Step 2: t-statistic\n\n$t = \\frac{b_1}{SE_{b_1}} = \\frac{0.067}{0.014952} = 4.4809947$\n\n## Proof!\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nget_regression_table(evals_lm) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 Ã— 7\n  term      estimate std_error statistic p_value lower_ci upper_ci\n  <chr>        <dbl>     <dbl>     <dbl>   <dbl>    <dbl>    <dbl>\n1 intercept    3.88      0.076     51.0        0    3.73     4.03 \n2 bty_avg      0.067     0.016      4.09       0    0.035    0.099\n```\n\n\n:::\n:::\n\n\n\n\n:::::::\n\n## How does R calculate the p-value?\n\n. . .\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(data = tibble(x = c(-5, 5)), \n       mapping = aes(x)) +\n  stat_function(fun = dt, \n                args = list(df = nrow(evals) - 2), \n                color = \"blue\", \n                linewidth = 1.5) +\n  labs(y = \"\", \n       x = \"t-statistic\") +\n  scale_y_continuous(breaks = NULL) +\n  geom_vline(xintercept = pull(t_stat), color = \"red\", linewidth = 1.5) +\n  my_theme\n```\n\n::: {.cell-output-display}\n![](week8-day1_files/figure-html/unnamed-chunk-9-1.png){fig-align='center' width=50%}\n:::\n:::\n\n\n\n\n\n. . .\n\n::: callout-note\n# Different $t$-distributions\n\nA $t$-distribution has a *slightly* different shape depending on the sample size. Technically, we are using a $t$-distribution with $n - 2$ degrees of freedom to get our p-value.\n:::\n\n# Did we get similar results between these methods?\n\n# Did we get similar results between these methods?\n\nWhy do you think that is?\n\n## Approximating the permutation distribution\n\n:::::: columns\n::: {.column width=\"40%\"}\nA $t$-distribution can be a reasonable approximation for the permutation distribution [if the normality condition is not violated]{.underline}.\n:::\n\n::: {.column width=\"5%\"}\n:::\n\n::: {.column width=\"55%\"}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(c(-5, 5),\n     c(0, dnorm(0)),\n      type = \"n\", \n     ylab = \"\", \n     xlab = \"\",\n     axes = FALSE\n     )\n\nat <- seq(-10, 10, 2)\naxis(1, at)\naxis(1, at - 1, rep(\"\", length(at)), tcl = -0.1)\nabline(h = 0)\nCOL. <- openintro::fadeColor(openintro::IMSCOL[\"blue\", \"full\"], c(\"FF\", \"89\", \"68\", \"4C\", \"33\"))\nCOLt <- openintro::fadeColor(openintro::IMSCOL[\"blue\", \"full\"], c(\"FF\", \"AA\", \"85\", \"60\", \"45\"))\nDF <- c(\"normal\", 8, 4, 2, 1)\nX <- seq(-10, 10, 0.02)\nY <- dnorm(X)\nlines(X, Y, col = COL.[1])\n\nfor (i in 2:5) {\n  Y <- dt(X, as.numeric(DF[i]))\n  lines(X, Y, col = COL.[i], lwd = 1.5)\n}\nlegend(2.5, 0.4,\n  legend = c(\n    DF[1],\n    paste(\"t, df = \", DF[2:5], sep = \"\")\n  ),\n  col = COL.,\n  text.col = COLt,\n  lty = rep(1, 5),\n  lwd = 1.5\n)\n```\n\n::: {.cell-output-display}\n![](week8-day1_files/figure-html/t-distribution-1.png){width=672}\n:::\n:::\n\n\n\n\n:::\n::::::\n\n## ![](images/gapminder.png)\n\n> What is the relationship between life expectancy GDP per capita?\n\n. . .\n\n-   Decide on a variable transformation\n-   Assess model conditions (L, I, N, E)\n-   Compare hypothesis test results between simulation-based methods and theory-based methods\n",
    "supporting": [
      "week8-day1_files/figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}